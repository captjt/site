<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>github</title>
   
   <link>https://github.com/jtaylor32</link>
   <description>My development story begins here.</description>
   <language>en-uk</language>
   <managingEditor> Jordan Taylor</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Go: Testing Approaches</title>
	  <link>//Go-Testing-Approaches</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-03-31T05:00:00+00:00</pubDate>
	  <guid>//Go-Testing-Approaches</guid>
	  <description><![CDATA[
	     <h2 id="software-testing-basics">Software Testing Basics</h2>

<p>Wikipedia says software testing is, <em>“an investigation conducted to provide stakeholders with information about the quality of the product or service under test. Software testing can also provide an objective, independent view of the software to allow the business to appreciate and understand the risks of software implementation.”</em> In layman’s terms, you can think of it as a solid foundation for why people should trust using your software. It also gives the developers a sense of what “should” work when it comes to the software working the way it’s meant to.</p>

<h3 id="testing--me">Testing + Me</h3>

<p>I’ve come from all sorts of different testing approaches during my short engineering life. I was first introduced to software testing in college. We were exposed to the test driven development style. I would recommend all software engineers to learn testing and the fundamentals of why testing is key to the success of the software we write. While working in industry I’ve done basic “by hand” testing – with no automated testing suites. Don’t be that person that says testing is enough when you just get out <code class="highlighter-rouge">curl</code> and hit your APIs!</p>

<p>On the opposite end of the spectrum – I’ve had full out exposure on setting up and managing a Jenkins build system on AWS for a team. On that we could run our test suites, run on multiple environments, all managed using Jenkins build agents. I’ve also used other CI/CD tools to do the same thing, basically they all do similar things.</p>

<p>I’ve developed and tested in many different languages (NodeJS, Python, Java, PHP, Racket, and others). The ease of use in some native testing frameworks are great for some languages but none have even come close to Go’s standard <a href="https://golang.org/pkg/testing/">testing</a> package. I cannot emphasize more on how happy I am to develop and <strong>TEST</strong> with Go. Testing is made so easy with Go – there should be no excuse why you can’t have a solid amount of tests for your packages or applications.</p>

<p><img src="./../assets/images/vader-unit-tests.jpg" alt="vader" /></p>

<h3 id="testing-things-in-go">Testing Things In Go</h3>

<p>Some of the tips I can give when writing tests in Go are use <code class="highlighter-rouge">slices</code> of <code class="highlighter-rouge">structs</code> to model your test cases. This keeps everything tidy and very easy to just write one loop to handle all the cases for a function. <em>Note</em> I’ve done this plenty before, but I see a lot of people trying to just do a crazy amount of <code class="highlighter-rouge">asserts</code> with new variables and <code class="highlighter-rouge">structs</code> made and honestly it’s just so time consuming and ugly.</p>

<p>Given this function we can show some example tests.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">func</span><span class="x"> </span><span class="n">stringer</span><span class="p">(</span><span class="n">in</span><span class="x"> </span><span class="kt">string</span><span class="p">)</span><span class="x"> </span><span class="kt">error</span><span class="x"> </span><span class="p">{</span><span class="x">
    </span><span class="k">if</span><span class="x"> </span><span class="n">in</span><span class="x"> </span><span class="o">==</span><span class="x"> </span><span class="s">""</span><span class="x"> </span><span class="p">{</span><span class="x">
        </span><span class="k">return</span><span class="x"> </span><span class="n">errors</span><span class="o">.</span><span class="n">New</span><span class="p">(</span><span class="s">"empty string"</span><span class="p">)</span><span class="x">
    </span><span class="p">}</span><span class="x"> </span><span class="k">else</span><span class="x"> </span><span class="k">if</span><span class="x"> </span><span class="n">in</span><span class="x"> </span><span class="o">==</span><span class="x"> </span><span class="s">"hi"</span><span class="x"> </span><span class="p">{</span><span class="x">
        </span><span class="k">return</span><span class="x"> </span><span class="n">errors</span><span class="o">.</span><span class="n">New</span><span class="p">(</span><span class="s">"bye"</span><span class="p">)</span><span class="x">
    </span><span class="p">}</span><span class="x">
    </span><span class="k">return</span><span class="x"> </span><span class="no">nil</span><span class="x">
</span><span class="p">}</span><span class="x">
</span></code></pre>
</div>

<p>The better way to test cases – you <code class="highlighter-rouge">name</code> your test case, <code class="highlighter-rouge">args</code> structures your inbound arguments, <code class="highlighter-rouge">want&lt;Anything&gt;</code> are the types you expect from those test cases. You can model your tests so easily with this approach! :)</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">type</span><span class="x"> </span><span class="n">args</span><span class="x"> </span><span class="k">struct</span><span class="x"> </span><span class="p">{</span><span class="x">
    </span><span class="n">in</span><span class="x"> </span><span class="kt">string</span><span class="x">
</span><span class="p">}</span><span class="x">
</span><span class="n">tests</span><span class="x"> </span><span class="o">:=</span><span class="x"> </span><span class="p">[]</span><span class="k">struct</span><span class="x"> </span><span class="p">{</span><span class="x">
    </span><span class="n">name</span><span class="x">    </span><span class="kt">string</span><span class="x">
    </span><span class="n">args</span><span class="x">    </span><span class="n">args</span><span class="x">
    </span><span class="n">wantErr</span><span class="x"> </span><span class="kt">bool</span><span class="x">
    </span><span class="c">// more wants can be added here ...</span><span class="x">
</span><span class="p">}{</span><span class="x">
    </span><span class="p">{</span><span class="x">
        </span><span class="n">name</span><span class="o">:</span><span class="x"> </span><span class="s">"test not empty string"</span><span class="p">,</span><span class="x">
        </span><span class="n">args</span><span class="o">:</span><span class="x"> </span><span class="n">args</span><span class="p">{</span><span class="x">
            </span><span class="n">in</span><span class="o">:</span><span class="x"> </span><span class="s">"test string"</span><span class="p">,</span><span class="x">
        </span><span class="p">},</span><span class="x">
        </span><span class="n">wantErr</span><span class="o">:</span><span class="x"> </span><span class="no">false</span><span class="p">,</span><span class="x">
    </span><span class="p">},</span><span class="x">
    </span><span class="p">{</span><span class="x">
        </span><span class="n">name</span><span class="o">:</span><span class="x"> </span><span class="s">"test hi string"</span><span class="p">,</span><span class="x">
        </span><span class="n">args</span><span class="o">:</span><span class="x"> </span><span class="n">args</span><span class="p">{</span><span class="x">
            </span><span class="n">in</span><span class="o">:</span><span class="x"> </span><span class="s">"hi"</span><span class="p">,</span><span class="x">
        </span><span class="p">},</span><span class="x">
        </span><span class="n">wantErr</span><span class="o">:</span><span class="x"> </span><span class="no">true</span><span class="p">,</span><span class="x">
    </span><span class="p">},</span><span class="x">
    </span><span class="p">{</span><span class="x">
        </span><span class="n">name</span><span class="o">:</span><span class="x"> </span><span class="s">"test string transformation"</span><span class="p">,</span><span class="x">
        </span><span class="n">args</span><span class="o">:</span><span class="x"> </span><span class="n">args</span><span class="p">{</span><span class="x">
            </span><span class="n">in</span><span class="o">:</span><span class="x"> </span><span class="s">"test empty string"</span><span class="p">,</span><span class="x">
        </span><span class="p">},</span><span class="x">
        </span><span class="n">wantErr</span><span class="o">:</span><span class="x"> </span><span class="no">true</span><span class="p">,</span><span class="x">
    </span><span class="p">},</span><span class="x">
</span><span class="p">}</span><span class="x">
</span></code></pre>
</div>

<p>After you generate your test cases you can run through a <code class="highlighter-rouge">for</code> loop and do some simple checks. You can also add customizable test cases based on conditionals you expect to have in your functions.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">for</span><span class="x"> </span><span class="n">_</span><span class="p">,</span><span class="x"> </span><span class="n">tt</span><span class="x"> </span><span class="o">:=</span><span class="x"> </span><span class="k">range</span><span class="x"> </span><span class="n">tests</span><span class="x"> </span><span class="p">{</span><span class="x">
    </span><span class="n">t</span><span class="o">.</span><span class="n">Run</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">name</span><span class="p">,</span><span class="x"> </span><span class="k">func</span><span class="p">(</span><span class="n">t</span><span class="x"> </span><span class="o">*</span><span class="n">testing</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="x"> </span><span class="p">{</span><span class="x">
        </span><span class="k">if</span><span class="x"> </span><span class="n">err</span><span class="x"> </span><span class="o">:=</span><span class="x"> </span><span class="n">stringer</span><span class="p">(</span><span class="n">tt</span><span class="o">.</span><span class="n">args</span><span class="o">.</span><span class="n">in</span><span class="p">);</span><span class="x"> </span><span class="p">(</span><span class="n">err</span><span class="x"> </span><span class="o">!=</span><span class="x"> </span><span class="no">nil</span><span class="p">)</span><span class="x"> </span><span class="o">!=</span><span class="x"> </span><span class="n">tt</span><span class="o">.</span><span class="n">wantErr</span><span class="x"> </span><span class="p">{</span><span class="x">
            </span><span class="n">t</span><span class="o">.</span><span class="n">Errorf</span><span class="p">(</span><span class="s">"stringer() error = %v, wantErr %v"</span><span class="p">,</span><span class="x"> </span><span class="n">err</span><span class="p">,</span><span class="x"> </span><span class="n">tt</span><span class="o">.</span><span class="n">wantErr</span><span class="p">)</span><span class="x">
        </span><span class="p">}</span><span class="x">
    </span><span class="p">})</span><span class="x">
</span><span class="p">}</span><span class="x">
</span></code></pre>
</div>

<h3 id="other-testing-advantages">Other Testing Advantages</h3>

<p>While I am sure there are arguments that you can do this same thing in other languages just as easy. I take it as a <em>“cherry on top”</em> – Go is already easy to use and extremely powerful.</p>

<h4 id="third-party-packages">Third Party Packages</h4>

<ul>
  <li>Notable packages:</li>
  <li><a href="https://github.com/stretchr/testify">testify</a></li>
  <li><a href="https://github.com/gavv/httpexpect">httpexpect</a></li>
  <li><a href="https://github.com/smartystreets/goconvey/">goconvey</a> – browser UI testing</li>
  <li><a href="https://github.com/golang/mock">gomock</a> – mocking framework</li>
  <li><a href="https://golang.org/pkg/net/http/httptest/">httptest</a> – Go’s native <code class="highlighter-rouge">httptest</code> package</li>
  <li>Awesome-go’s <a href="https://awesome-go.com/#testing">testing</a> section</li>
</ul>

<h4 id="editor-integrations">Editor Integrations</h4>

<p>There are some extremely powerful and robust editor tools surrounding the Go language. These all give the power to the users – doing auto linting, generation for test cases, auto building, etc.! I cannot be more thankful for all of the abstractions automatically for my development process.</p>

<p>Here are a few I use or hear good things about.</p>

<ul>
  <li><a href="https://github.com/Microsoft/vscode-go">vscode-go**</a></li>
  <li><a href="https://github.com/fatih/vim-go">vim-go**</a></li>
  <li><a href="https://github.com/DisposaBoy/GoSublime">GoSublime</a></li>
  <li>Awesome-go’s <a href="https://awesome-go.com/#editor-plugins">editor-plugins</a> section</li>
</ul>

<p>** ones I use regularly</p>

	  ]]></description>
	</item>

	<item>
	  <title>Kubernetes: Complexities Simplified Pt. 1</title>
	  <link>//Kubernetes-Complexities-Simplified-Pt-1</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-03-22T05:00:00+00:00</pubDate>
	  <guid>//Kubernetes-Complexities-Simplified-Pt-1</guid>
	  <description><![CDATA[
	     <h2 id="why-are-microservices-hard">Why Are Microservices Hard?</h2>

<p>Conceptually when moving to microservices it will solve a lot of major problems we face with monolithic applications. The overhead that I mentioned in the later portion of <a href="http://jt.codes/Migration-to-Microservices">Introduction on Migrating to Microservices</a> can be hard to wrap our heads around. We need to establish tracing, monitoring, load balancing, service discovery, dynamic request routing, TLS, circuit breaking and more. <strong>What are these things and what do they even mean?!</strong></p>

<h3 id="complexities-say-what">Complexities… Say What??</h3>

<p>What is distributed tracing, service discovery, circuit breaking…? – The list goes on. One of these, distributed tracing, is one of the most underrated tools to help with monitoring our services. Distributed tracing is key to what is going on within a single call into our microservice architecture. We can follow the lifespan of a request, see what’s going on and where things are getting bottled up.</p>

<p><em>Distributed tracing provides a holistic view of requests transiting through multiple services, allowing for immediate identification of latency issues.</em></p>

<h3 id="one-tool-to-rule-them-all">One Tool To Rule Them All</h3>

<blockquote>
  <p>“Enter Linkerd”</p>
</blockquote>

<p><a href="https://linkerd.io/">Linkerd</a> is an open source project that is built off of Twitter’s <a href="https://twitter.github.io/finagle/">finagle</a>. It doesn’t lock developers into a single JVM, .NET, JS, etc. language. It’s core principle is catering to developers as they migrated to these complex system architectures.</p>

<p>Linkerd solves many of the fundamental problems we face with microservices. While distributed tracing is at the center of this article. I will, in the near future, go more in depth about other complexities Linkerd solves.</p>

<h3 id="hands-on">Hands On</h3>

<p>The Buoyant <a href="https://blog.buoyant.io/">blog</a> is a fantastic way to get started with Linkerd. They truly simpilfy how things are working under the covers and give real examples of how to incorporate Linkerd into your architecture.</p>

<p>Since <a href="https://k8s.io/">Kubernetes</a> is the <a href="https://www.youtube.com/watch?v=3MyYhSnHGm0">“Linux of the Cloud”</a> I am going to walkthrough a quick example of using <a href="http://zipkin.io/">Zipkin</a> and Linkerd – running on Kubernetes as a DaemonSet. Zipkin simply is a distributed tracing tool. The source code for this walkthrough is <a href="https://github.com/jtaylor32/woogidi-woogidi-woogidi">here</a>.</p>

<h3 id="kubernetes-creating-the-services-and-pods">Kubernetes: Creating the Services and Pods</h3>

<p>You can set your <code class="highlighter-rouge">namespaces</code> separately, but this is a simple tutorial on how to stand up an app insides Kubernetes and have traffic routed and traced using Linkerd + Zipkin. Note: Commands will be based on a <a href="https://github.com/kubernetes/minikube">minikube</a> cluster – can be ported to actual Kubernetes seamlessly.</p>

<h4 id="installconfigure-linkerd">Install/Configure Linkerd</h4>

<p>This command will apply a ConfigMap for Linkerd as a DaemonSet to route traffic in and out of specific ports.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>kubectl apply -f https://raw.githubusercontent.com/jtaylor32/woogidi-woogidi-woogidi/master/k8s-configs/linkerd-zipkin.yml
</code></pre>
</div>

<p>Once the service is running you can open the admin dashboard. This will be where you can monitor inbound/outbound traffic; as well as configure your routing within the “dtab” and other cool features.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>minikube service l5d
</code></pre>
</div>

<p><img src="./../assets/images/linkerd-dashboard.jpg" alt="linkerd-dashboard" />
<em>Linkerd Dashboard</em></p>

<p>Run the service. This should create a replication set of 3 pods named “woogidi” (reminiscing on <a href="https://en.wikipedia.org/wiki/Rocket_Power">Rocket Power</a> days). This service will be listening on <em>port 8080</em>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>kubectl apply -f https://raw.githubusercontent.com/jtaylor32/woogidi-woogidi-woogidi/master/k8s-configs/woogidi-woogidi-woogidi.yml
</code></pre>
</div>

<p>To check if the service is working correctly we can do a simple curl commands.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># Set the L5D_INGRESS_LB so we can http_proxy to the service </span>
<span class="nv">L5D_INGRESS_LB</span><span class="o">=</span><span class="k">$(</span>minikube service l5d --url | head -n1<span class="k">)</span>

<span class="nv">http_proxy</span><span class="o">=</span><span class="nv">$L5D_INGRESS_LB</span> curl -XPOST -d <span class="s1">'{"gnarly": "Otto"}'</span> http://woogidi/

<span class="o">{</span><span class="s2">"response"</span>:<span class="s2">"let's crank Otto"</span><span class="o">}</span>
</code></pre>
</div>

<p>Sick. Us and Otto are going to go shred some gnar! This is all because the Linkerd service that is running is configured to route traffic to this service. It acts as a service discovery tool as well!</p>

<p>But what if something is getting bottlenecked somewhere in the request chain or is failing and we can’t detect that? Here is where we need to configure Zipkin inside our cluster.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>kubectl apply -f https://raw.githubusercontent.com/jtaylor32/woogidi-woogidi-woogidi/master/k8s-configs/zipkin.yml
</code></pre>
</div>

<p>Open the Zipkin dashboard once the service starts.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>minikube service zipkin
</code></pre>
</div>

<p>The dashboard allows us to do some filtering on requests that are going through the Linkerd service. We can also dive into specific requests and calls within Zipkin.</p>

<h4 id="snapshots-of-zipkin-interface">Snapshots of Zipkin Interface</h4>

<p><img src="./../assets/images/zipkin-dashboard.jpg" alt="zipkin-dashboard" />
<em>Zipkin Dashboard</em></p>

<p><img src="./../assets/images/zipkin-single-call.jpg" alt="zipkin-single-call" />
<em>Single Request</em></p>

<p><img src="./../assets/images/zipkin-details.jpg" alt="zipkin-details" />
<em>Single Trace Call</em></p>

<h3 id="whats-next">What’s Next?</h3>

<p>Now we can monitor, tracing and do some simple service discovery within Kubernetes we need to expand and have log monitoring, ingress (load balancing), and other features solved.</p>

<ul>
  <li>
    <p>Log monitoring will include – <a href="https://github.com/prometheus">Prometheus</a> + <a href="https://github.com/grafana/grafana">Grafana</a>.</p>
  </li>
  <li>
    <p>Ingress will include a way to traffic our requests to Linkerd using <a href="https://github.com/nginx/nginx">nginx</a> as our proxy.</p>
  </li>
</ul>

<blockquote>
  <p>Feel free to reach out to me and ask questions or bring up other topics you’d like me to write about!</p>
</blockquote>

<p><img src="./../assets/images/tito-later.jpg" alt="later-bro!" /></p>

	  ]]></description>
	</item>

	<item>
	  <title>Introduction on Migrating to Microservices</title>
	  <link>//Migration-to-Microservices</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-03-09T05:00:00+00:00</pubDate>
	  <guid>//Migration-to-Microservices</guid>
	  <description><![CDATA[
	     <h2 id="why-microservices">Why Microservices?</h2>

<p>This is an obvious question raised when applications or companies move to a microservices approach. There is a massive use case for the migration to microservices. The perfect time is you are at a scale or a place in your application’s life cycle where you cannot iterate fast enough on top of your monolithic application. There are so many more resources out there on when or why to switch to this architecture it’s not really worth “beating a dead horse” on the subject.</p>

<h4 id="technologies-to-migrate-with">Technologies to Migrate With?</h4>

<p>You might be wondering where to start and what approach to take – if you have the luxury to migrate and refactor everything without a time constraint you’re lucky! Majority of us don’t have that luxury and really don’t have the full buy in from our management or superiors to even “fix” our already working application. Invest in your products and invest in the future of your products is all I can say. This means containers and efficiency. Containers are here.. and here to stay. When I say that majority of companies or teams are just dabbling in containers and what to do with <strong>Docker or Rkt</strong> (“Rocket” – a CoreOS product) it’s understandable but <strong>invest</strong> in modern technologies. Containers are a pivotal foundation for the future of applications. Containers decouple applications from operating systems, which means that users can have a clean and minimal Linux operating system and run everything else in one or more isolated container. Invest in yourselves and your application’s future start getting up to speed with containers it is so simple to spin up applications with these to proof them for teams/management. The ease of use to manage and bundle up applications is a major selling point!</p>

<h4 id="after-approval">After Approval</h4>

<p>Uh-oh… Now what right? You need a team to fully focus and sell out on these technologies. Regardless of the learning curve you will probably face when moving to containers and orchestration tools you will make it through it! The best things in life aren’t always the easiest things to come by – but a team focused on the future of the application and in turn the company’s future success.</p>

<p><img src="./../assets/images/small-team.jpg" alt="team" class="img-responsive" /></p>

<p>If you are a small team pick a uniformed language to start with that everyone is comfortable developing in. A key feature you will need to take into account is how easy is it to run on Linux. I am an advocate for Go but also love NodeJS and Python. Do what’s best for you team and make sure you know that microservices don’t lock you into one single language it helps at an initial migration having a single or a couple uniform languages for developers to agree on.</p>

<h4 id="container-orchestration">Container Orchestration</h4>

<p>The biggest decision you will make after the initial migration movement is how in the world will you manage all of these containerized services.</p>

<blockquote>
  <p>You might think that containers will solve all problems. Managing containers manually is simply out of the question. When it comes to microservices, containers are roughly 5% of the problem. Container management or orchestration is the last 95%.</p>
</blockquote>

<p>Invest in some time in researching which tool or tools fit your application’s use cases. Here are a list of some of the major self-hosted orchestration tools – if you want something like an already hosted service of these things <em>Google, Mesosphere, Rancher</em> and others support enterprise platforms for these kinds of things already.</p>

<p>Self-Hosted</p>

<ul>
  <li><a href="https://kubernetes.io/">Kubernetes</a>
    <ul>
      <li>Came out of Google – built based on Google’s “Borg” project</li>
      <li>Backed and supported by majority of the leading tech companies like</li>
    </ul>
  </li>
  <li><a href="https://dcos.io/">DC/OS</a>
    <ul>
      <li>Product built around Apache Mesos</li>
      <li>Blog <a href="https://mesosphere.com/blog/2016/04/19/open-source-dcos/">post</a> on the release of DC/OS</li>
      <li>Backed and supported by companies like Microsoft, Accenture, and others</li>
    </ul>
  </li>
  <li><a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a>
    <ul>
      <li>Not as widely used in the community</li>
    </ul>
  </li>
</ul>

<p>There might be other options out there but a big thing to note when migrating to a microservice architecture is the communities. Kubernetes has been the biggest player in this space and is backed by <strong>A LOT</strong> of companies using these technologies. Many companies using Kubernetes support the tool by giving back to the open sourced code as well.</p>

<h4 id="service-interactions">Service Interactions</h4>

<p>More architecture decisions you will have to make are how your services will interact and managing an API gateway into your services. There are major complexities that come with microservices interacting with each other and how to monitor what is going on – but there are tools out there to solve this. Later on I will talk about tooling decisions you will have to make when managing <strong>service discovery, tracing, monitoring, transporting, circuit breakers</strong> and other things.</p>

<p>Don’t feel overwhelmed when making the leap of migrating architectures it’s an <strong>investment</strong>.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Elasticsearch At A Glance</title>
	  <link>//Elasticsearch-At-A-Glance</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-02-14T05:00:00+00:00</pubDate>
	  <guid>//Elasticsearch-At-A-Glance</guid>
	  <description><![CDATA[
	     <h2 id="why-elasticsearch">Why Elasticsearch?</h2>

<p>Elasticsearch has some major upsides to it when using it on as a developer.  It takes almost four minutes to stand up on a CentOS server and even quicker on my development machine (Mac OSX with Homebrew). Regardless whether or not you are using it in those environments it is still very quick and easy to do an install with configurations. Configurations are made EASY. Elasticsearch will, based on your settings, do automatic cluster replication on indexes you create. You can tell it that you want five, ten, three, whatever of how many replication shards you want it to make. This will increase the productivity you have along with performance and fault tolerance of the storage layer. You will not need to worry about diving in and setting up major in-depth configurations when it really is meant to be abstracted out for you - that helps developers work on other aspects of the applications running on Elasticsearch. Having the fault tolerance of having many shards replicated to however many nodes you have inside of your cluster per index is huge. This might seem scary at first when it does this for you out of the box, but when you dive into the real stuff and see what it’s doing - it’s quite nice.</p>

<p>JSON everything. Web development and applications have been revolutionized by RESTful and JSON type of manipulation of data. Majority of people either know REST of have used it one way or another. Elasticsearch is catering to the modern technologies. Because JSON is such a huge and easy way to store data many developers love interacting with it. All of the queries, responses, mappings, anything is done with Elasticsearch is through JSON! (HUGE simplicity for people to hit the ground running)</p>

<p>I cannot think of anything that has been difficult learning how to interact or use Elasticsearch. The community is massive around it and honestly cannot see anything wrong with moving towards it.</p>

<p>Here are some excerpts from elastic.co (official company behind ES) and others regarding the technology…</p>

<p>“Elasticsearch provides the ability to subdivide your index into multiple pieces called shards. When you create an index, you can simply define the number of shards that you want. Each shard is in itself a fully-functional and independent “index” that can be hosted on any node in the cluster.”  – Elasticsearch official docs</p>

<h3 id="sharding-concepts-">Sharding concepts …</h3>

<p>It allows you to horizontally split/scale your content volume
It allows you to distribute and parallelize operations across shards (potentially on multiple nodes) thus increasing performance/throughput</p>

<h3 id="replication-concepts-">Replication concepts …</h3>

<p>It provides high availability in case a shard/node fails. For this reason, it is important to note that a replica shard is never allocated on the same node as the original/primary shard that it was copied from.
It allows you to scale out your search volume/throughput since searches can be executed on all replicas in parallel.</p>

<h3 id="use-cases----real-companies-using-es">Use Cases – Real Companies Using ES!</h3>

<p>Ebay – <a href="https://www.elastic.co/videos/ebay-and-elasticsearch-this-is-not-small-data">this-is-not-small-data</a></p>

<p>Goldman Sachs – <a href="https://www.elastic.co/elasticon/conf/2016/sf/how-the-elastic-stack-changed-goldman-sachs">stack-changed-goldman-sachs</a></p>

<p>Netflix – <a href="https://www.elastic.co/elasticon/conf/2016/sf/dude-where-are-my-messages-message-analytics-at-netflix">message-analytics-at-netflix</a></p>

<p>Facebook – <a href="https://www.elastic.co/elasticon/2015/sf/from-hackathon-to-production-elasticsearch-facebook">hackathon-to-production-facebook</a></p>

<p>Many more <a href="https://www.elastic.co/use-cases">here</a> and what has driven companies to Elasticsearch (many of which transitioned from Solr)</p>

	  ]]></description>
	</item>

	<item>
	  <title>Jenkins 2.0 - Pipelines with NodeJS</title>
	  <link>//Jenkins-2.0-Pipeline-NodeJS</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-02-03T05:00:00+00:00</pubDate>
	  <guid>//Jenkins-2.0-Pipeline-NodeJS</guid>
	  <description><![CDATA[
	     <h2 id="future-of-jenkins-the-jenkinsfile">Future of Jenkins: The Jenkinsfile</h2>

<p>The future of Jenkins and CI/CD is having “Pipelines” as code. Delivery pipelines are thought of as a first-class entity in Jenkins 2.0. Just like your typical <code class="highlighter-rouge">.yml</code> configuration file from Travis, Circle or other popular CI tools - Jenkins 2.0 has been released with a similar concept. Jenkins has the capability with a Pipeline plugin to use Pipelines as code in <code class="highlighter-rouge">Jenkinsfile</code>s. Users can now model their software delivery pipelines much easier. Another key feature is that the <code class="highlighter-rouge">Jenkinsfile</code> can be checked into version control.</p>

<h2 id="creating-a-pipeline-for-nodejs-application">Creating A Pipeline For NodeJS Application</h2>

<h3 id="prerequisites">Prerequisites**</h3>

<ul>
  <li>Setup Jenkins with AWS plugin for build agents</li>
  <li>Configure Github plugin to receive PUSH webhooks from git hosted repository</li>
  <li>Configure NodeJS plugin to install selected NodeJS versions for each Jenkins build</li>
</ul>

<p>** future tutorial for configurations</p>

<h3 id="nodejs-application">NodeJS Application</h3>

<p>When building a modern web application many people are moving towards NodeJS and the community around NodeJS to power the future of technologies. One practice I definitely advocate especially in JavaScript, because of it’s dynamic typing system, is TDD so you have clarity on how your application “should” run and perform. I am a big advocate for testing with <a href="https://github.com/facebook/jest">Jest</a> but there are also test libraries like Mocha, Chai, PhantomJS, and others to accomplish TDD.</p>

<h3 id="sample-application">Sample Application</h3>

<p>I have a small <a href="https://github.com/expressjs/express">express.js</a> server application that we will use to walk through this pipeline tutorial.**</p>

<p>Note: this application really is only to proof tests and run a “Hello World” express application.</p>

<p>** Github repository: <a href="https://github.com/jtaylor32/jenkins-pipeline-express">here</a></p>

<h3 id="application-is-ready">Application Is Ready</h3>

<p>After our application is ready to push to Testing, Staging, Production, etc. we need to have a simple way for Jenkins to orchestrate our workflow. Jenkinsfiles can easily get us up and running with pipelines. We start with a specific <strong>node</strong>, or server, in our pipeline to fire off our build process on that machine. Because we are using AWS EC2s – we can make our node’s labels specific to a build agent inside of our Manage Jenkins &gt; Configure System.</p>

<p>Here we have a build agent up called ‘testing’ that will run the first process in our pipeline.</p>

<h4 id="testing-node">Testing Node</h4>
<ol>
  <li>use our NodeJS plugin to install version 7.4.0</li>
  <li>checkout code from version control</li>
  <li>install dependencies for running tests</li>
  <li>run tests on testing environment</li>
  <li>publish our results inside of our Jenkins job’s build page</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">node</span><span class="o">(</span><span class="s1">'testing'</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">stage</span><span class="o">(</span><span class="s1">'Initialize'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Initializing...'</span>
        <span class="kt">def</span> <span class="n">node</span> <span class="o">=</span> <span class="n">tool</span> <span class="nl">name:</span> <span class="s1">'Node-7.4.0'</span><span class="o">,</span> <span class="nl">type:</span> <span class="s1">'jenkins.plugins.nodejs.tools.NodeJSInstallation'</span>
        <span class="n">env</span><span class="o">.</span><span class="na">PATH</span> <span class="o">=</span> <span class="s2">"${node}/bin:${env.PATH}"</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Getting source code...'</span>
        <span class="n">checkout</span> <span class="n">scm</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Building dependencies...'</span>
        <span class="n">sh</span> <span class="s1">'npm i'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Testing...'</span>
        <span class="n">sh</span> <span class="s1">'npm test'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Publish'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Publishing Test Coverage...'</span>
		<span class="n">publishHTML</span> <span class="o">(</span><span class="nl">target:</span> <span class="o">[</span>
			<span class="nl">allowMissing:</span> <span class="kc">false</span><span class="o">,</span>
			<span class="nl">alwaysLinkToLastBuild:</span> <span class="kc">false</span><span class="o">,</span>
			<span class="nl">keepAll:</span> <span class="kc">true</span><span class="o">,</span>
			<span class="nl">reportDir:</span> <span class="s1">'coverage/lcov-report'</span><span class="o">,</span>
			<span class="nl">reportFiles:</span> <span class="s1">'index.html'</span><span class="o">,</span>
			<span class="nl">reportName:</span> <span class="s2">"Application Test Coverage"</span>
		<span class="o">])</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<p>If anything inside of our ‘testing’ node fails it will not move on to the next ‘staging’ node. So if our <code class="highlighter-rouge">npm test</code> fails it will publish that and Jenkins will see that tests failed do not move this application to staging.</p>

<p>We can also add in manual approvals inside of our pipelines with the <code class="highlighter-rouge">input</code> function.</p>

<p><code class="highlighter-rouge">input 'Is the application ready for Staging?'</code></p>

<p>We won’t add that inside of here but there are really awesome things that pipelines can do for us you can check out later on… Onto Staging!</p>

<h4 id="staging-node">Staging Node</h4>
<ol>
  <li>use our NodeJS plugin to install version 7.4.0</li>
  <li>checkout code from version control</li>
  <li>install PM2 globally</li>
  <li>install dependencies</li>
  <li>run tests on staging environment</li>
  <li>stop and start our application with PM2</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">node</span><span class="o">(</span><span class="s1">'staging'</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">stage</span><span class="o">(</span><span class="s1">'Initialize'</span><span class="o">){</span>
        <span class="n">echo</span> <span class="s1">'Initializing...'</span>
        <span class="kt">def</span> <span class="n">node</span> <span class="o">=</span> <span class="n">tool</span> <span class="nl">name:</span> <span class="s1">'Node-7.4.0'</span><span class="o">,</span> <span class="nl">type:</span> <span class="s1">'jenkins.plugins.nodejs.tools.NodeJSInstallation'</span>
        <span class="n">env</span><span class="o">.</span><span class="na">PATH</span> <span class="o">=</span> <span class="s2">"${node}/bin:${env.PATH}"</span>

        <span class="n">sh</span> <span class="s2">"node -v"</span>

        <span class="c1">// set environment variables</span>
        <span class="n">env</span><span class="o">.</span><span class="na">VARIABLE_1</span><span class="o">=</span><span class="s2">"10"</span>
        <span class="n">env</span><span class="o">.</span><span class="na">VARIABLE_2</span><span class="o">=</span><span class="s2">"7"</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Getting source code...'</span>
        <span class="n">checkout</span> <span class="n">scm</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'PM2 Install'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Installing PM2 to run application as daemon...'</span>
        <span class="n">sh</span> <span class="s2">"npm install pm2 -g"</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Building dependencies...'</span>
        <span class="n">sh</span> <span class="s1">'npm i'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Testing...'</span>
        <span class="n">sh</span> <span class="s1">'npm test'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Run Application'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Stopping old process to run new process...'</span>
        <span class="n">sh</span> <span class="s1">'''
        # show our env variables
        env

        npm run pm2-stop
        npm run pm2-start
        '''</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<h4 id="environment-variables">Environment Variables</h4>
<p>If you noticed inside of the staging node I set <code class="highlighter-rouge">env</code> variables specific to that node so that I can run my Express application with those configurations and not have to worry about hard coding that into my code.</p>

<p>Here is a snippet from my express application that we can reference those environment variables. This is key when dealing with multiple environments and application settings for production applications – write our code once kind of thing.</p>

<pre><code class="language-JavaScript">const envOne = process.env.VARIABLE_1;
const envTwo = process.env.VARIABLE_2;
</code></pre>

<h3 id="wrapping-up">Wrapping Up</h3>

<p>You can do advanced features in pipeline builds to stash, archive, spin up or tear down servers, and many more – but this should be a simple way to show how we can do it with a basic starter application. I will put out another article on how to integrate AWS, NodeJS, Github and other useful plugins so that we can production ready for CI/CD with Jenkins.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Serving Jenkins with TLS-Encryption Using Caddy</title>
	  <link>//Serving-Jenkins-with-TLS-and-Caddy</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-01-27T05:00:00+00:00</pubDate>
	  <guid>//Serving-Jenkins-with-TLS-and-Caddy</guid>
	  <description><![CDATA[
	     <h2 id="what-is-caddy">What is Caddy?</h2>

<p>Caddy, or as others may know Caddyserver, is a web server similar to nginx or Apache that serves files over HTTP. HTTP is the basic and standard way people are served/distributed website content. Caddy’s main purpose is to streamline how developers authenticate their web deployment process. It is the only web server software that will automatically encrypt your site with SSL/TLS encryption. This means that without too much knowledge behind web security and how to secure your server - developers can receive and authenticate TLS certifications automatically. We are in the age of many, many technologies throughout the full stack of web development it is hard to keep up with everything outside of development processes. Caddy is here to save us from the cumbersome process of deploying our applications properly AND with encryption included.</p>

<h2 id="caddy-has-options">Caddy Has Options</h2>

<p>Other than the automatic TLS encryption, one of the coolest things the community around Caddy has been developing is “Directives”. These can be thought of as plugins or extensions to make developer’s lives even more easy. Things like file JWT authentication, CORS (Cross Origin Resource Sharing), AWS Lambda features, and others right out of these easily configured extensions.</p>

<h2 id="serving-jenkins-with-caddy">Serving Jenkins With Caddy</h2>

<p>Because Caddy is such an amazing software product I tend to lean more towards using it everywhere I can. With that being said, I did find it a bit quirky when settings it up to serve a CI/CD application – Jenkins.</p>

<p>Jenkins is a fantastic open source product that has been a leader in the CI/CD community ever since being released as the first one of it’s kind. It’s a Java based project that when configured properly can do some pretty robust pipelining and custom build processes. I will not go over how to setup Jenkins on your machine there are some fantastic resources already out there on this kind of thing – but <a href="https://trycrmr.github.io/hubpress.io/2017/01/20/Automated-Testing-Using-Jenkins-on-AWS.html">here</a> is a great walk through on how to setup Jenkins on CentOS 7 in your AWS environment.</p>

<h2 id="caddy">Caddy</h2>

<p>Caddy comes out with releases on a regular basis this download version might not be up to date, but I will try to keep this as up to date as possible with newer things that change with Caddy and/or Jenkins when configuring the two together.</p>

<h2 id="initial-install">Initial Install</h2>

<p>Download the tarball for the release of caddy you want. <strong>NOTE:</strong> You can also do this from their site @ <a href="https://www.caddyserver.com">caddyserver</a> and hand jam a custom built Caddy + directives over to your server.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>wget https://caddyserver.com/download/builds/172401104141966/caddy_linux_amd64_custom.tar.gz
tar xf caddy_linux_amd64_custom.tar.gz
</code></pre>
</div>

<p>We are going to need to copy our <code class="highlighter-rouge">caddy</code> binary to our local/bin to be in our executable PATH. After that we will need to change the owner of the binary to <code class="highlighter-rouge">root</code> so that we can enable a <em>system service</em> to start/stop/restart/etc. our caddy server.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo cp caddy /usr/local/bin/
sudo chown root:root /usr/local/bin/caddy
sudo chmod 755 /usr/local/bin/caddy
</code></pre>
</div>

<h2 id="configuring-caddy-and-groupsusers">Configuring Caddy and Groups/Users</h2>

<p>This will setup Caddy to be able to bind to our HTTP and SSL ports without being <code class="highlighter-rouge">root</code>. <strong>Don’t forget to configure the firewalls on your server to allow for traffic through both ports 80 and 433.</strong> This is easily done in AWS through security groups and on the CentOS server through <em>firewalld</em>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo setcap <span class="s1">'cap_net_bind_service=+ep'</span> /usr/local/bin/caddy
</code></pre>
</div>

<p>We then need to setup the group, user and directories that Caddy will need to have.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo groupadd -g 33 www-data
sudo useradd <span class="se">\</span>
  -g www-data --no-user-group <span class="se">\</span>
  --home-dir /var/www --no-create-home <span class="se">\</span>
  --shell /usr/sbin/nologin <span class="se">\</span>
  --system --uid 33 www-data

sudo mkdir /etc/caddy
sudo chown -R root:www-data /etc/caddy
sudo mkdir /etc/ssl/caddy
sudo chown -R www-data:root /etc/ssl/caddy
sudo chmod 0770 /etc/ssl/caddy
</code></pre>
</div>

<h2 id="the-caddyfile">The Caddyfile</h2>

<p>Sample Caddyfile with subdomain wildcard (*.jt.codes)</p>

<p>This will proxy all of the root traffic from port 80 to port 8080 where our Jenkins application is running – while passing the host information that most backend applications would expect when we specify <code class="highlighter-rouge">transparent</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>jenkins.jt.codes {
	proxy / :8080 {
		transparent
	}
}
</code></pre>
</div>

<p>We need to next move our Caddyfile and give it proper ownership to be used. <strong>NOTE:</strong> I like to keep my Caddyfile in my <code class="highlighter-rouge">$HOME</code> directory so it’s easily found/changed in the future - just make sure you copy the Caddyfile into the <code class="highlighter-rouge">/etc/caddy/</code> directory if you alter it again and restart the service.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo cp /path/to/Caddyfile /etc/caddy/
sudo chown www-data:www-data /etc/caddy/Caddyfile
sudo chmod 444 /etc/caddy/Caddyfile
</code></pre>
</div>

<h2 id="note-serving-from-varwww">Note Serving from <strong>/var/www/</strong></h2>

<p>If we wanted to host our sites inside of a home directory similar to how <em>nginx and Apache</em> do we can also configure an <code class="highlighter-rouge">/var/www/</code> site as well. Although because we are just going to reverse proxy to our running Jenkins application on <strong>port 8080</strong> we will not have to serve content through that configuration.</p>

<h2 id="caddy-as-a-service">Caddy as a Service</h2>

<p>One thing we wanted to make sure we had is a Caddy systemd service configuration – so next we will configure a <code class="highlighter-rouge">caddy.service</code> file. Similar to our Caddyfile I like to keep a reference file in my $HOME directory to easily change and configure anything again.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">cd</span> <span class="nv">$HOME</span>
<span class="gp">$ </span>vim caddy.service
</code></pre>
</div>

<p>and inside of our <code class="highlighter-rouge">caddy.service</code> file we will paste this …</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[Unit]
Description=Caddy HTTP/2 web server
Documentation=https://caddyserver.com/docs
After=network-online.target
Wants=network-online.target systemd-networkd-wait-online.service

[Service]
Restart=on-failure
StartLimitInterval=86400
StartLimitBurst=5

; User and group the process will run as.
User=www-data
Group=www-data

; Letsencrypt-issued certificates will be written to this directory.
Environment=CADDYPATH=/etc/ssl/caddy

; Always set "-root" to something safe in case it gets forgotten in the Caddyfile.
ExecStart=/usr/local/bin/caddy -log stdout -agree=true -conf=/etc/caddy/Caddyfile -root=/var/tmp
ExecReload=/bin/kill -USR1 $MAINPID

; Limit the number of file descriptors; see `man systemd.exec` for more limit settings.
LimitNOFILE=1048576
; Unmodified caddy is not expected to use more than that.
LimitNPROC=64

; Use private /tmp and /var/tmp, which are discarded after caddy stops.
PrivateTmp=true
; Use a minimal /dev
PrivateDevices=true
; Hide /home, /root, and /run/user. Nobody will steal your SSH-keys.
ProtectHome=true
; Make /usr, /boot, /etc and possibly some more folders read-only.
ProtectSystem=full
; … except /etc/ssl/caddy, because we want Letsencrypt-certificates there.
;   This merely retains r/w access rights, it does not add any new. Must still be writable on the host!
ReadWriteDirectories=/etc/ssl/caddy

; The following additional security directives only work with systemd v229 or later.
; They further retrict privileges that can be gained by caddy. Uncomment if you like.
; Note that you may have to add capabilities required by any plugins in use.
;CapabilityBoundingSet=CAP_NET_BIND_SERVICE
;AmbientCapabilities=CAP_NET_BIND_SERVICE
;NoNewPrivileges=true

[Install]
WantedBy=multi-user.target
</code></pre>
</div>

<p>A couple things to note when we are looking at that configuration file - we are going to store our SSL certificates inside of the <code class="highlighter-rouge">/etc/ssl/caddy</code> directory. <strong>Make sure you keep these certificates secure and backed up.</strong></p>

<p>Caddy will auto detect when our certificates need to be renewed but we must make sure we do keep them secure from people.</p>

<h2 id="onto-the-magic">Onto the Magic</h2>

<p><strong>A quick note:</strong> make sure inside of your <strong>Jenkins &gt; Configure System</strong> you setup your <code class="highlighter-rouge">Jenkins URL</code> to the “<em>https</em>” version of your domains. So for us it will be “<em>https://jenkins.jt.codes</em>”.</p>

<p><strong>NOTE:</strong> make sure to add the “s” after “http” – this will through reverse proxy issues with the Jenkins application.</p>

<p>We are going to copy our <code class="highlighter-rouge">caddy.service</code> file to the <code class="highlighter-rouge">system</code> directory, establish proper ownership/permissions and start out Caddy service.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo cp caddy.service /etc/systemd/system/
sudo chown root:root /etc/systemd/system/caddy.service
sudo chmod 744 /etc/systemd/system/caddy.service
sudo systemctl daemon-reload
sudo systemctl start caddy.service
</code></pre>
</div>

<p>To allow for the Caddy service to start on reboot we can <code class="highlighter-rouge">enable</code> it.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo systemctl <span class="nb">enable </span>caddy.service
</code></pre>
</div>

<p>The service works just like any other <code class="highlighter-rouge">systemd</code> service and we can <strong>start, restart, and stop</strong> - along with seeing the status of the running service with <strong>status</strong>.</p>

<h2 id="going-forward">Going Forward</h2>

<p>Once you verified and established that your Jenkins server is now SSL encrypted - you can dance around for a second. I must say Caddy has been a huge savior when it comes to getting an application out there and secured properly. You can find Caddy on github @ <a href="https://github.com/mholt/caddy">Caddy</a> or <a href="https://github.com/caddyserver">caddyserver</a>’s Organization.</p>

<p>HUGE S/o to <a href="https://github.com/mholt">Matt Holt</a> for doing some amazing things and creating this awesome tech.</p>

<p>I will put out more examples and resources on Caddy, the ACME protocol and how to use Caddy with other types of applications.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Python & VS Code</title>
	  <link>//Settings-Up-Python-Environment-VS-Code</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-01-18T05:00:00+00:00</pubDate>
	  <guid>//Settings-Up-Python-Environment-VS-Code</guid>
	  <description><![CDATA[
	     <h3 id="working-with-vs-code">Working With VS Code</h3>

<p>There are a lot of IDE/Editors out there for Python and I keep getting asked from colleages about how I setup my environment locally. Instead of trying to chain emails, slack/rocketchat each other with long conversations this article will help solve some problems.</p>

<p>VS Code is a fantastic editor that I have been using full-time for about 6 months now (converted from Sublime). I have also used PyCharm and Atom with Python projects and I do think they are viable options as well, but I always end up back with VS Code no matter how hard I try to force myself out of it. I think the flexibility I have with VS Code to develop all types of applications in one place is where I fell in love. I use it for Go, Python, PHP, JavaScript and Scala projects so far.</p>

<p>On to the setup…</p>

<h3 id="setup">Setup</h3>

<p>The biggest thing I try and promote with Python and projects are <strong>virtual environments</strong>. They provide developers the flexibility to have many different Python versions specific to an application. Another promotion I have for Python is <strong>Python 3 – use it</strong>… don’t stray from it. I don’t advocate for people to develop anything in <strong>legacy</strong> Python (2.7). Python 2.7 is so slow that Google even compiles their Python 2.7 code to Go to improve performance <a href="https://github.com/google/grumpy">grumpy</a>. Python 3 fixes a ton of the performance problems that come up in 2.7 – use Python 3!</p>

<p>When you are first setting up your Python project setup your virtualenv with a tool like <strong>pyvenv</strong> … in your trusty <em>Terminal</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># "env" will be the directory that your local dependencies will be install under`</span>
<span class="gp">$ </span>pyvenv env
<span class="c"># this will activate your virtualenv`</span>
<span class="gp">$ </span><span class="nb">source </span>env/bin/activate
<span class="c"># You should see (env) at the beginning of the line in your terminal session now.</span>
</code></pre>
</div>

<p>It’s best practice to have all of your dependencies stored in a file named <code class="highlighter-rouge">requirements.txt</code> at the root of your project’s structure. Here is a sample <em>requirements.txt</em> file with production dependencies I have for a small flask application. Yours obviously will have different dependencies depending on the Python packages you need for you application.</p>

<p><em>requirements.txt</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code># Everything needed in production

wheel

# Flask
Flask
Flask-RESTful
blinker

# Database
Flask-SQLAlchemy
psycopg2
GeoAlchemy2

# Migrations
Flask-Migrate

# Deployment
gunicorn
gevent

# Utils
simplejson
</code></pre>
</div>

<p>To install all these dependencies we just do a simple <code class="highlighter-rouge">pip install -r requirements.txt</code> <strong>BUT</strong> we also need to make sure we have our project’s virtual environment activated before we do the installation.</p>

<p>Your dependencies will be install in that <strong>env</strong> directory and we can locate them if we want to just by looking through the <code class="highlighter-rouge">env/lib/python3.x/site-packages</code> directory. On to the VS Code integration ==» WOO.</p>

<h3 id="vs-code">VS Code</h3>

<p>The first thing you will need to install is a extension called <a href="https://marketplace.visualstudio.com/items?itemName=donjayamanne.python">Python</a>. You can install it with the extension panel on the left side navigation (last button on the bottom). And search for Python – it’s the most downloaded extension when you search for Python. You can read through the docs on that extension to do more custom things but here are the main settings you will need to paste in your <strong>Workplace Settings/User Settings</strong> under your <strong>Preferences</strong>.</p>

<pre><code class="language-JavaScript">// Python specific
"python.pythonPath": "${workspaceRoot}/env/bin/python3.6",
"python.autoComplete.extraPaths": [
    "${workspaceRoot}/env/lib/python3.6/site-packages"
],
"python.devOptions": [
    "DEBUG"
],
"python.linting.pylintEnabled": true,
"python.linting.flake8Enabled": false,
"python.linting.pylintArgs": "pylint --load-plugins pylint-flask",
"python.formatting.provider": "autopep8",
"python.unitTest.unittestEnabled": false,
"python.unitTest.pyTestEnabled": false,
"python.unitTest.nosetestsEnabled": false,
</code></pre>

<p>Paste that into your <strong>settings.json</strong> file that will come up when you select <strong>User Settings</strong> or <strong>Workplace Settings</strong>. The <strong>KEY</strong> to those settings is the “python.pythonPath” and “python.autoComplete.extraPaths” you have to point that to the <em>Path</em> you have to your local virtual environment folders. Also! I will recommend you keep project settings specific to your <strong>Workplace Settings</strong> because you might have many different Python versions when going from project to project and keeping the <strong>User Settings</strong> might break the paths.</p>

<p>There are some custom settings like the linting/testings you can do inside of the editor as well. I tend to stick with my terminal to run external things like that but you can play around with it – this should give you the basic VS Code environment for developing with Python.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Twenty-Sixteen</title>
	  <link>//Twenty-Sixteen</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-01-03T05:00:00+00:00</pubDate>
	  <guid>//Twenty-Sixteen</guid>
	  <description><![CDATA[
	     <h3 id="in-review">2016 in Review</h3>

<p>Twenty-sixteen was definitely a year to remember. I constantly look back thinking about all the things that changed in my life from graduating from undergrad, finishing my baseball career, to pushing production code the first day on the job, leading and contributing to some fantastic applications within the State Department… it’s been a crazy year.</p>

<p>When it comes to growing in my technology life I was so back and forth with languages. When I first came out of college I had a ton of experience with PHP and Java so obviously I loved what I knew. Little did I start leaning towards the more “hip” languages like Node and JavaScript.  I was the typical JS fanboy (and still am) but it was a complete change in mindset of how concurrency worked without having to architect major multi threaded applications.  To say the least it was a hit.  I got to enjoy the great complexities of the JavaScript language at it’s finest using it in the frontend with ReactJS and also on the server side.</p>

<p>But then, I decided to look into Python because it wasn’t new and it was a solid language that people have been developing with for year.  It was hitting a soft spot in my heart because it really was so simple and easy for me to take all the CS concepts I already knew and apply them super easy and fast with a scripting language.  I could iterate on applications pretty fast without having to handle JavaScript callbacks with promises and async/await.  I fell in love with it I could also do some awesome machine learning odds and ends with packages like numpy, scikit-learn, etc.  The biggest thing I missed from Node was the concurrency though - as much as a pain callbacks were to wrap my head around at first.  Enter the room… Go.</p>

<p>I don’t really remember how Golang (“Go”) was introduced to me but I must say it’s been an adventure to say the least.  The community around Go is growing more and more everyday - not many people really understand how powerful Go can be.  I love the concurrency model - no more promises and callback pyramids you get thrown into like you did in JavaScript; there aren’t crazy multiple threading issues you run into like in Java.  The magic is in the CSP-Model (Communicating Sequential Processes) – you have these channels that bridge messages sent between “goroutines” that are running concurrent processes.  You wait and block while messages are getting sent through these “channels” it’s a beautiful and simple complexity once you understand how powerful they can be.  There are so many amazing things that are being built in Go - it seems that the future of distributed systems and development is being written in Go.  The big players in the tech business are using it and backing it – Uber, DropBox, Docker, DigitalOcean, and many more… oh and Google (they made/maintain it).</p>

<p>Learning more about all things technology is my passion I couldn’t have imagined how much I’ve learned since starting my professional career but it’s been fantastic so far and I can’t wait for the next year’s challenges!  Polyglot is the best mentality I have – I think the best builders use all their tools to their best abilities.  Having a strong base of many languages is at the core of what I think it means to be a software engineer.</p>

<h4 id="the-year-to-come">The Year to Come</h4>

<p>Top things to do in 2017</p>

<ul>
  <li>Expand more on containers and container orchestration (Docker + Kubernetes?)</li>
  <li>More open source development…currently none :(</li>
  <li>Look into open source projects…per previous TODO</li>
  <li>Expand on more ReactJS applications (or insert favorite JS Framework)</li>
  <li>Get more into “non” SQL based databases
    <ul>
      <li>Previous usage of Elasticsearch and Neo4J</li>
    </ul>
  </li>
  <li>Go, Go, and more Go (learning Go has been awesome so far – keep GOing!)</li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Creating A RESTful API w/ Elasticsearch</title>
	  <link>//Creating-A-RESTful-API-w-Elasticsearch</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2016-12-20T05:00:00+00:00</pubDate>
	  <guid>//Creating-A-RESTful-API-w-Elasticsearch</guid>
	  <description><![CDATA[
	     <h4 id="in-progress">(In Progress)</h4>

<h3 id="objective">Objective:</h3>
<p>We want to establish a way to query <em><strong>Elasticsearch</strong></em> through a RESTful API’s endpoints.</p>

<h3 id="pre-requirements">Pre-Requirements</h3>

<ul>
  <li>Python 3+
    <ul>
      <li>Knowledge of virtual environments, dependency management with <strong>PIP</strong></li>
    </ul>
  </li>
  <li>Elasticsearch 2.X
    <ul>
      <li>Install Elasticseach on Centos 7 –&gt; <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-centos-7">es-on-centos-7</a></li>
      <li><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a></li>
    </ul>
  </li>
</ul>

<h3 id="wsgi-application-flask">WSGI Application (Flask)</h3>

<p>We are going to be using the micro-framework, <em>flask</em>, in this tutorial.  We will use the <em>elasticsearch-dsl-py</em> package that elastic created to interact with elasticsearch at a more high level abstraction.</p>

<h4 id="project-structure">Project Structure</h4>

<div class="highlighter-rouge"><pre class="highlight"><code>.
├── app/
│   ├── index.md
│   ├── api/
│   │   ├── __init__.py
│   │   ├── resources/
│   │   │   ├── __init__.py
│   │   │   ├── search.py
│   │   ├── search_config/
│   │   │   ├── __init__.py
│   ├── __init__.py
│   ├── config.py
│   ├── extensions.py
│   ├── helpers.py
├── env/
├── requirements/
│   ├── development.txt
│   ├── production.txt
├── tests/
│   ├── unit/
│   │   ├── test_*.py
│   ├── __init__.py
│   ├── conftest.py
├── manage.py
├── requirements.txt
├── runtime.txt
├── setup.cfg
</code></pre>
</div>

<p>To be continued…</p>

	  ]]></description>
	</item>

	<item>
	  <title>Elasticsearch Info/Resources</title>
	  <link>//Elasticsearch</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2016-12-13T05:00:00+00:00</pubDate>
	  <guid>//Elasticsearch</guid>
	  <description><![CDATA[
	     <p>Elasticsearch is a “NRT” (Near Real Time) search platform which means the data that is being ingested is nearly searchable within &lt; 1 second.</p>

<h2 id="basic-concepts">Basic Concepts</h2>

<p>You can learn more about Elasticsearch and it’s basic concepts at their <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html">docs</a></p>

<h5 id="cluster">Cluster</h5>
<p>The cluster concept in ES is that you can have a bunch of nodes (or servers) that hold all your data together.</p>

<h5 id="node">Node</h5>
<p>A node is a single elasticsearch server (or service) that is running holding a collection of indexes and data regarding each index.</p>

<h5 id="index">Index</h5>
<p>An index is thought of as a “database” in relational terms. It is a higher level concept that can be thought of as similar characteristics for the document data.</p>

<h5 id="type">Type</h5>
<p>Types can be thought of as “tables” in relational terms. It is a more definied catagorization of data for each document stored in ES.
One way to think about it is you have a higher level index of “User Data” and you can have “Order Data”, “Comment Data”, etc.</p>

<h5 id="document">Document</h5>
<p>These are the lowest level catagorization of document data in ES. Think of these as “rows” in a relational mindset.  You can have attributes in each document that describe the data’s features.</p>

<h5 id="shardingreplication">Sharding/Replication</h5>
<p>We can do multiple sharding instances on indexes if we are storing huge amount of document data in them. <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html#_shards_amp_replicas">Sharding</a></p>

<h2 id="resources">Resources</h2>

<h3 id="elasticsearch">Elasticsearch</h3>
<ul>
  <li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Quick Reference</a></li>
</ul>

<h3 id="elasticseach-language-specific">Elasticseach (language specific)</h3>
<ul>
  <li><a href="http://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a></li>
  <li><a href="http://elasticsearch-py.readthedocs.io/en/master/">elasticsearch-py</a></li>
  <li><a href="https://www.elastic.co/products/elasticsearch">elasticsearch</a></li>
  <li><a href="https://olivere.github.io/elastic/">elastic</a></li>
  <li><a href="https://godoc.org/gopkg.in/olivere/elastic.v3">more elastic</a></li>
</ul>

<h3 id="external-backend-frameworks">External Backend Frameworks</h3>
<ul>
  <li><a href="http://flask.pocoo.org/">flask</a></li>
  <li><a href="http://flask-restful-cn.readthedocs.io/en/0.3.5/">flask-restful</a></li>
  <li><a href="https://gin-gonic.github.io/gin/">gin</a></li>
</ul>

<h3 id="small-examples">Small Examples</h3>
<ul>
  <li><a href="https://github.com/jtaylor32/elasticsearch-restful-api">rest-api</a></li>
  <li><a href="https://github.com/jtaylor32/elasticsearch-bulk-ingestion">bulk-ingestion</a></li>
</ul>

<h3 id="web-scrapers">Web Scrapers</h3>
<ul>
  <li><a href="http://nutch.apache.org/">nutch</a></li>
  <li><a href="https://scrapy.org/">scrapy</a></li>
  <li><a href="https://github.com/yhat/scrape">scrape</a></li>
</ul>

<h3 id="blogsbooks">Blogs/Books</h3>
<ul>
  <li><a href="http://docs.python-guide.org/en/latest/scenarios/scrape/">python-scraping</a></li>
  <li><a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/">more-python-scraping</a></li>
  <li><a href="https://schier.co/blog/2015/04/26/a-simple-web-scraper-in-go.html">go-scraping</a></li>
  <li><a href="http://shop.oreilly.com/product/0636920034391.do">Web Scraping with Python</a></li>
  <li><a href="https://qbox.io/blog/scraping-the-web-with-nutch-for-elasticsearch">Scraping with Nutch</a></li>
</ul>

<h3 id="other-es-articles">Other ES Articles</h3>
<ul>
  <li><a href="http://goinbigdata.com/working-with-elasticsearch-in-go/">es-in-go</a></li>
  <li><a href="http://126kr.com/article/5c4jgpiwtwp">testing-go-es</a></li>
  <li><a href="https://msftstack.wordpress.com/2016/02/18/making-a-book-search-engine-in-python-and-elasticsearch/">python-with-es</a></li>
  <li>more to come…</li>
</ul>

<p>continued…</p>

	  ]]></description>
	</item>


</channel>
</rss>
