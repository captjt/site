<?xml version="1.0" encoding="UTF-8" ?>

<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
   
      <title>github</title>
   
   <link>https://github.com/jtaylor32</link>
   <description>My development story begins here.</description>
   <language>en-uk</language>
   <managingEditor> Jordan Taylor</managingEditor>
   <atom:link href="rss" rel="self" type="application/rss+xml" />
   
	<item>
	  <title>Introduction on Migrating to Microservices</title>
	  <link>//Migration-to-Microservices</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-02-14T05:00:00+00:00</pubDate>
	  <guid>//Migration-to-Microservices</guid>
	  <description><![CDATA[
	     <h2 id="why-microservices">Why Microservices?</h2>

<p>This is an obvious question raised when applications or companies move to a microservices approach. There is a massive use case for the migration to microservices. The perfect time is you are at a scale or a place in your application’s life cycle where you cannot iterate fast enough on top of your monolithic application. There are so many more resources out there on when or why to switch to this architecture it’s not really worth “beating a dead horse” on the subject.</p>

<h4 id="technologies-to-migrate-with">Technologies to Migrate With?</h4>

<p>You might be wondering where to start and what approach to take – if you have the luxury to migrate and refactor everything without a time constraint you’re lucky! Majority of us don’t have that luxury and really don’t have the full buy in from our management or superiors to even “fix” our already working application. Invest in your products and invest in the future of your products is all I can say. This means containers and efficiency. Containers are here.. and here to stay. When I say that majority of companies or teams are just dabbling in containers and what to do with Docker or Rkt (“Rocket” – a CoreOS product) it’s understandable but <strong>invest</strong> in modern technologies. Invest in yourselves and your application’s future start getting up to speed with containers it is so simple to spin up applications with these to proof them for teams/management. The ease of use to manage and bundle up applications is a major selling point!</p>

<h4 id="after-approval">After Approval</h4>

<p>Uh-oh… Now what right? You need a team to fully focus and sell out on these technologies. Regardless of the learning curve you will probably face when moving to containers and orchestration tools you will make it through it! The best things in life aren’t always the easiest things to come by – but a team focused on the future of the application and in turn the company’s future success.</p>

<p><img src="./../assets/images/small-team.jpg" alt="team" class="img-responsive" /></p>

<p>If you are a small team pick a uniformed language to start with that everyone is comfortable developing in. A key feature you will need to take into account is how easy is it to run on Linux. I am an advocate for Go but also love NodeJS and Python. Do what’s best for you team and make sure you know that microservices don’t lock you into one single language it helps at an initial migration having a single or a couple uniform languages for developers to agree on.</p>

<h4 id="container-orchestration">Container Orchestration</h4>

<p>The biggest decision you will make after the initial migration movement is how in the world will you manage all of these containerized services. Invest in some time in researching which tool or tools fit your application’s use cases. Here are a list of some of the major self-hosted orchestration tools – if you want something like an already hosted service of these things Google, Mesosphere, Rancher and others support enterprise platforms for these kinds of things already.</p>

<p>Self-Hosted</p>

<ul>
  <li><a href="https://kubernetes.io/">Kubernetes</a>
    <ul>
      <li>Came out of Google – built based on Google’s “Borg” project</li>
      <li>Backed and supported by majority of the leading tech companies like</li>
    </ul>
  </li>
  <li><a href="https://dcos.io/">DC/OS</a>
    <ul>
      <li>Product built around Apache Mesos</li>
      <li>Blog <a href="https://mesosphere.com/blog/2016/04/19/open-source-dcos/">post</a> on the release of DC/OS</li>
      <li>Backed and supported by companies like Microsoft, Accenture, and others</li>
    </ul>
  </li>
  <li><a href="https://docs.docker.com/engine/swarm/">Docker Swarm</a>
    <ul>
      <li>Not as widely used in the community</li>
    </ul>
  </li>
</ul>

<p>There might be other options out there but a big thing to note when migrating to a microservice architecture is the communities. Kubernetes has been the biggest player in this space and is backed by <strong>A LOT</strong> of companies using these technologies. Many companies using Kubernetes support the tool by giving back to the open sourced code as well.</p>

<h4 id="service-interactions">Service Interactions</h4>

<p>More architecture decisions you will have to make are how your services will interact and managing an API gateway into your services. There are major complexities that come with microservices interacting with each other and how to monitor what is going on – but there are tools out there to solve this. Later on I will talk about tooling decisions you will have to make when managing service discovery, tracing, monitoring, transporting, circuit breakers (retries) and other things.</p>

<p>Don’t feel overwhelmed when making the leap of migrating architectures it’s an <strong>investment</strong>.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Elasticsearch At A Glance</title>
	  <link>//Elasticsearch-At-A-Glance</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-02-14T05:00:00+00:00</pubDate>
	  <guid>//Elasticsearch-At-A-Glance</guid>
	  <description><![CDATA[
	     <h2 id="why-elasticsearch">Why Elasticsearch?</h2>

<p>Elasticsearch has some major upsides to it when using it on as a developer.  It takes almost four minutes to stand up on a CentOS server and even quicker on my development machine (Mac OSX with Homebrew). Regardless whether or not you are using it in those environments it is still very quick and easy to do an install with configurations. Configurations are made EASY. Elasticsearch will, based on your settings, do automatic cluster replication on indexes you create. You can tell it that you want five, ten, three, whatever of how many replication shards you want it to make. This will increase the productivity you have along with performance and fault tolerance of the storage layer. You will not need to worry about diving in and setting up major in-depth configurations when it really is meant to be abstracted out for you - that helps developers work on other aspects of the applications running on Elasticsearch. Having the fault tolerance of having many shards replicated to however many nodes you have inside of your cluster per index is huge. This might seem scary at first when it does this for you out of the box, but when you dive into the real stuff and see what it’s doing - it’s quite nice.</p>

<p>JSON everything. Web development and applications have been revolutionized by RESTful and JSON type of manipulation of data. Majority of people either know REST of have used it one way or another. Elasticsearch is catering to the modern technologies. Because JSON is such a huge and easy way to store data many developers love interacting with it. All of the queries, responses, mappings, anything is done with Elasticsearch is through JSON! (HUGE simplicity for people to hit the ground running)</p>

<p>I cannot think of anything that has been difficult learning how to interact or use Elasticsearch. The community is massive around it and honestly cannot see anything wrong with moving towards it.</p>

<p>Here are some excerpts from elastic.co (official company behind ES) and others regarding the technology…</p>

<p>“Elasticsearch provides the ability to subdivide your index into multiple pieces called shards. When you create an index, you can simply define the number of shards that you want. Each shard is in itself a fully-functional and independent “index” that can be hosted on any node in the cluster.”  – Elasticsearch official docs</p>

<h3 id="sharding-concepts-">Sharding concepts …</h3>

<p>It allows you to horizontally split/scale your content volume
It allows you to distribute and parallelize operations across shards (potentially on multiple nodes) thus increasing performance/throughput</p>

<h3 id="replication-concepts-">Replication concepts …</h3>

<p>It provides high availability in case a shard/node fails. For this reason, it is important to note that a replica shard is never allocated on the same node as the original/primary shard that it was copied from.
It allows you to scale out your search volume/throughput since searches can be executed on all replicas in parallel.</p>

<h3 id="use-cases----real-companies-using-es">Use Cases – Real Companies Using ES!</h3>

<p>Ebay – <a href="https://www.elastic.co/videos/ebay-and-elasticsearch-this-is-not-small-data">this-is-not-small-data</a></p>

<p>Goldman Sachs – <a href="https://www.elastic.co/elasticon/conf/2016/sf/how-the-elastic-stack-changed-goldman-sachs">stack-changed-goldman-sachs</a></p>

<p>Netflix – <a href="https://www.elastic.co/elasticon/conf/2016/sf/dude-where-are-my-messages-message-analytics-at-netflix">message-analytics-at-netflix</a></p>

<p>Facebook – <a href="https://www.elastic.co/elasticon/2015/sf/from-hackathon-to-production-elasticsearch-facebook">hackathon-to-production-facebook</a></p>

<p>Many more <a href="https://www.elastic.co/use-cases">here</a> and what has driven companies to Elasticsearch (many of which transitioned from Solr)</p>

	  ]]></description>
	</item>

	<item>
	  <title>Jenkins 2.0 - Pipelines with NodeJS</title>
	  <link>//Jenkins-2.0-Pipeline-NodeJS</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-02-03T05:00:00+00:00</pubDate>
	  <guid>//Jenkins-2.0-Pipeline-NodeJS</guid>
	  <description><![CDATA[
	     <h2 id="future-of-jenkins-the-jenkinsfile">Future of Jenkins: The Jenkinsfile</h2>

<p>The future of Jenkins and CI/CD is having “Pipelines” as code. Delivery pipelines are thought of as a first-class entity in Jenkins 2.0. Just like your typical <code class="highlighter-rouge">.yml</code> configuration file from Travis, Circle or other popular CI tools - Jenkins 2.0 has been released with a similar concept. Jenkins has the capability with a Pipeline plugin to use Pipelines as code in <code class="highlighter-rouge">Jenkinsfile</code>s. Users can now model their software delivery pipelines much easier. Another key feature is that the <code class="highlighter-rouge">Jenkinsfile</code> can be checked into version control.</p>

<h2 id="creating-a-pipeline-for-nodejs-application">Creating A Pipeline For NodeJS Application</h2>

<h3 id="prerequisites">Prerequisites**</h3>

<ul>
  <li>Setup Jenkins with AWS plugin for build agents</li>
  <li>Configure Github plugin to receive PUSH webhooks from git hosted repository</li>
  <li>Configure NodeJS plugin to install selected NodeJS versions for each Jenkins build</li>
</ul>

<p>** future tutorial for configurations</p>

<h3 id="nodejs-application">NodeJS Application</h3>

<p>When building a modern web application many people are moving towards NodeJS and the community around NodeJS to power the future of technologies. One practice I definitely advocate especially in JavaScript, because of it’s dynamic typing system, is TDD so you have clarity on how your application “should” run and perform. I am a big advocate for testing with <a href="https://github.com/facebook/jest">Jest</a> but there are also test libraries like Mocha, Chai, PhantomJS, and others to accomplish TDD.</p>

<h3 id="sample-application">Sample Application</h3>

<p>I have a small <a href="https://github.com/expressjs/express">express.js</a> server application that we will use to walk through this pipeline tutorial.**</p>

<p>Note: this application really is only to proof tests and run a “Hello World” express application.</p>

<p>** Github repository: <a href="https://github.com/jtaylor32/jenkins-pipeline-express">here</a></p>

<h3 id="application-is-ready">Application Is Ready</h3>

<p>After our application is ready to push to Testing, Staging, Production, etc. we need to have a simple way for Jenkins to orchestrate our workflow. Jenkinsfiles can easily get us up and running with pipelines. We start with a specific <strong>node</strong>, or server, in our pipeline to fire off our build process on that machine. Because we are using AWS EC2s – we can make our node’s labels specific to a build agent inside of our Manage Jenkins &gt; Configure System.</p>

<p>Here we have a build agent up called ‘testing’ that will run the first process in our pipeline.</p>

<h4 id="testing-node">Testing Node</h4>
<ol>
  <li>use our NodeJS plugin to install version 7.4.0</li>
  <li>checkout code from version control</li>
  <li>install dependencies for running tests</li>
  <li>run tests on testing environment</li>
  <li>publish our results inside of our Jenkins job’s build page</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">node</span><span class="o">(</span><span class="s1">'testing'</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">stage</span><span class="o">(</span><span class="s1">'Initialize'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Initializing...'</span>
        <span class="kt">def</span> <span class="n">node</span> <span class="o">=</span> <span class="n">tool</span> <span class="nl">name:</span> <span class="s1">'Node-7.4.0'</span><span class="o">,</span> <span class="nl">type:</span> <span class="s1">'jenkins.plugins.nodejs.tools.NodeJSInstallation'</span>
        <span class="n">env</span><span class="o">.</span><span class="na">PATH</span> <span class="o">=</span> <span class="s2">"${node}/bin:${env.PATH}"</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Getting source code...'</span>
        <span class="n">checkout</span> <span class="n">scm</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Building dependencies...'</span>
        <span class="n">sh</span> <span class="s1">'npm i'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Testing...'</span>
        <span class="n">sh</span> <span class="s1">'npm test'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Publish'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Publishing Test Coverage...'</span>
		<span class="n">publishHTML</span> <span class="o">(</span><span class="nl">target:</span> <span class="o">[</span>
			<span class="nl">allowMissing:</span> <span class="kc">false</span><span class="o">,</span>
			<span class="nl">alwaysLinkToLastBuild:</span> <span class="kc">false</span><span class="o">,</span>
			<span class="nl">keepAll:</span> <span class="kc">true</span><span class="o">,</span>
			<span class="nl">reportDir:</span> <span class="s1">'coverage/lcov-report'</span><span class="o">,</span>
			<span class="nl">reportFiles:</span> <span class="s1">'index.html'</span><span class="o">,</span>
			<span class="nl">reportName:</span> <span class="s2">"Application Test Coverage"</span>
		<span class="o">])</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<p>If anything inside of our ‘testing’ node fails it will not move on to the next ‘staging’ node. So if our <code class="highlighter-rouge">npm test</code> fails it will publish that and Jenkins will see that tests failed do not move this application to staging.</p>

<p>We can also add in manual approvals inside of our pipelines with the <code class="highlighter-rouge">input</code> function.</p>

<p><code class="highlighter-rouge">input 'Is the application ready for Staging?'</code></p>

<p>We won’t add that inside of here but there are really awesome things that pipelines can do for us you can check out later on… Onto Staging!</p>

<h4 id="staging-node">Staging Node</h4>
<ol>
  <li>use our NodeJS plugin to install version 7.4.0</li>
  <li>checkout code from version control</li>
  <li>install PM2 globally</li>
  <li>install dependencies</li>
  <li>run tests on staging environment</li>
  <li>stop and start our application with PM2</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="n">node</span><span class="o">(</span><span class="s1">'staging'</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">stage</span><span class="o">(</span><span class="s1">'Initialize'</span><span class="o">){</span>
        <span class="n">echo</span> <span class="s1">'Initializing...'</span>
        <span class="kt">def</span> <span class="n">node</span> <span class="o">=</span> <span class="n">tool</span> <span class="nl">name:</span> <span class="s1">'Node-7.4.0'</span><span class="o">,</span> <span class="nl">type:</span> <span class="s1">'jenkins.plugins.nodejs.tools.NodeJSInstallation'</span>
        <span class="n">env</span><span class="o">.</span><span class="na">PATH</span> <span class="o">=</span> <span class="s2">"${node}/bin:${env.PATH}"</span>

        <span class="n">sh</span> <span class="s2">"node -v"</span>

        <span class="c1">// set environment variables</span>
        <span class="n">env</span><span class="o">.</span><span class="na">VARIABLE_1</span><span class="o">=</span><span class="s2">"10"</span>
        <span class="n">env</span><span class="o">.</span><span class="na">VARIABLE_2</span><span class="o">=</span><span class="s2">"7"</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Checkout'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Getting source code...'</span>
        <span class="n">checkout</span> <span class="n">scm</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'PM2 Install'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Installing PM2 to run application as daemon...'</span>
        <span class="n">sh</span> <span class="s2">"npm install pm2 -g"</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Build'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Building dependencies...'</span>
        <span class="n">sh</span> <span class="s1">'npm i'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Test'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Testing...'</span>
        <span class="n">sh</span> <span class="s1">'npm test'</span>
    <span class="o">}</span>

    <span class="n">stage</span><span class="o">(</span><span class="s1">'Run Application'</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">echo</span> <span class="s1">'Stopping old process to run new process...'</span>
        <span class="n">sh</span> <span class="s1">'''
        # show our env variables
        env

        npm run pm2-stop
        npm run pm2-start
        '''</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre>
</div>

<h4 id="environment-variables">Environment Variables</h4>
<p>If you noticed inside of the staging node I set <code class="highlighter-rouge">env</code> variables specific to that node so that I can run my Express application with those configurations and not have to worry about hard coding that into my code.</p>

<p>Here is a snippet from my express application that we can reference those environment variables. This is key when dealing with multiple environments and application settings for production applications – write our code once kind of thing.</p>

<pre><code class="language-JavaScript">const envOne = process.env.VARIABLE_1;
const envTwo = process.env.VARIABLE_2;
</code></pre>

<h3 id="wrapping-up">Wrapping Up</h3>

<p>You can do advanced features in pipeline builds to stash, archive, spin up or tear down servers, and many more – but this should be a simple way to show how we can do it with a basic starter application. I will put out another article on how to integrate AWS, NodeJS, Github and other useful plugins so that we can production ready for CI/CD with Jenkins.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Serving Jenkins with TLS-Encryption Using Caddy</title>
	  <link>//Serving-Jenkins-with-TLS-and-Caddy</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-01-27T05:00:00+00:00</pubDate>
	  <guid>//Serving-Jenkins-with-TLS-and-Caddy</guid>
	  <description><![CDATA[
	     <h2 id="what-is-caddy">What is Caddy?</h2>

<p>Caddy, or as others may know Caddyserver, is a web server similar to nginx or Apache that serves files over HTTP. HTTP is the basic and standard way people are served/distributed website content. Caddy’s main purpose is to streamline how developers authenticate their web deployment process. It is the only web server software that will automatically encrypt your site with SSL/TLS encryption. This means that without too much knowledge behind web security and how to secure your server - developers can receive and authenticate TLS certifications automatically. We are in the age of many, many technologies throughout the full stack of web development it is hard to keep up with everything outside of development processes. Caddy is here to save us from the cumbersome process of deploying our applications properly AND with encryption included.</p>

<h2 id="caddy-has-options">Caddy Has Options</h2>

<p>Other than the automatic TLS encryption, one of the coolest things the community around Caddy has been developing is “Directives”. These can be thought of as plugins or extensions to make developer’s lives even more easy. Things like file JWT authentication, CORS (Cross Origin Resource Sharing), AWS Lambda features, and others right out of these easily configured extensions.</p>

<h2 id="serving-jenkins-with-caddy">Serving Jenkins With Caddy</h2>

<p>Because Caddy is such an amazing software product I tend to lean more towards using it everywhere I can. With that being said, I did find it a bit quirky when settings it up to serve a CI/CD application – Jenkins.</p>

<p>Jenkins is a fantastic open source product that has been a leader in the CI/CD community ever since being released as the first one of it’s kind. It’s a Java based project that when configured properly can do some pretty robust pipelining and custom build processes. I will not go over how to setup Jenkins on your machine there are some fantastic resources already out there on this kind of thing – but <a href="https://trycrmr.github.io/hubpress.io/2017/01/20/Automated-Testing-Using-Jenkins-on-AWS.html">here</a> is a great walk through on how to setup Jenkins on CentOS 7 in your AWS environment.</p>

<h2 id="caddy">Caddy</h2>

<p>Caddy comes out with releases on a regular basis this download version might not be up to date, but I will try to keep this as up to date as possible with newer things that change with Caddy and/or Jenkins when configuring the two together.</p>

<h2 id="initial-install">Initial Install</h2>

<p>Download the tarball for the release of caddy you want. <strong>NOTE:</strong> You can also do this from their site @ <a href="https://www.caddyserver.com">caddyserver</a> and hand jam a custom built Caddy + directives over to your server.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>wget https://caddyserver.com/download/builds/172401104141966/caddy_linux_amd64_custom.tar.gz
tar xf caddy_linux_amd64_custom.tar.gz
</code></pre>
</div>

<p>We are going to need to copy our <code class="highlighter-rouge">caddy</code> binary to our local/bin to be in our executable PATH. After that we will need to change the owner of the binary to <code class="highlighter-rouge">root</code> so that we can enable a <em>system service</em> to start/stop/restart/etc. our caddy server.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo cp caddy /usr/local/bin/
sudo chown root:root /usr/local/bin/caddy
sudo chmod 755 /usr/local/bin/caddy
</code></pre>
</div>

<h2 id="configuring-caddy-and-groupsusers">Configuring Caddy and Groups/Users</h2>

<p>This will setup Caddy to be able to bind to our HTTP and SSL ports without being <code class="highlighter-rouge">root</code>. <strong>Don’t forget to configure the firewalls on your server to allow for traffic through both ports 80 and 433.</strong> This is easily done in AWS through security groups and on the CentOS server through <em>firewalld</em>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo setcap <span class="s1">'cap_net_bind_service=+ep'</span> /usr/local/bin/caddy
</code></pre>
</div>

<p>We then need to setup the group, user and directories that Caddy will need to have.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo groupadd -g 33 www-data
sudo useradd <span class="se">\</span>
  -g www-data --no-user-group <span class="se">\</span>
  --home-dir /var/www --no-create-home <span class="se">\</span>
  --shell /usr/sbin/nologin <span class="se">\</span>
  --system --uid 33 www-data

sudo mkdir /etc/caddy
sudo chown -R root:www-data /etc/caddy
sudo mkdir /etc/ssl/caddy
sudo chown -R www-data:root /etc/ssl/caddy
sudo chmod 0770 /etc/ssl/caddy
</code></pre>
</div>

<h2 id="the-caddyfile">The Caddyfile</h2>

<p>Sample Caddyfile with subdomain wildcard (*.jt.codes)</p>

<p>This will proxy all of the root traffic from port 80 to port 8080 where our Jenkins application is running – while passing the host information that most backend applications would expect when we specify <code class="highlighter-rouge">transparent</code>.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>jenkins.jt.codes {
	proxy / :8080 {
		transparent
	}
}
</code></pre>
</div>

<p>We need to next move our Caddyfile and give it proper ownership to be used. <strong>NOTE:</strong> I like to keep my Caddyfile in my <code class="highlighter-rouge">$HOME</code> directory so it’s easily found/changed in the future - just make sure you copy the Caddyfile into the <code class="highlighter-rouge">/etc/caddy/</code> directory if you alter it again and restart the service.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo cp /path/to/Caddyfile /etc/caddy/
sudo chown www-data:www-data /etc/caddy/Caddyfile
sudo chmod 444 /etc/caddy/Caddyfile
</code></pre>
</div>

<h2 id="note-serving-from-varwww">Note Serving from <strong>/var/www/</strong></h2>

<p>If we wanted to host our sites inside of a home directory similar to how <em>nginx and Apache</em> do we can also configure an <code class="highlighter-rouge">/var/www/</code> site as well. Although because we are just going to reverse proxy to our running Jenkins application on <strong>port 8080</strong> we will not have to serve content through that configuration.</p>

<h2 id="caddy-as-a-service">Caddy as a Service</h2>

<p>One thing we wanted to make sure we had is a Caddy systemd service configuration – so next we will configure a <code class="highlighter-rouge">caddy.service</code> file. Similar to our Caddyfile I like to keep a reference file in my $HOME directory to easily change and configure anything again.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span><span class="nb">cd</span> <span class="nv">$HOME</span>
<span class="gp">$ </span>vim caddy.service
</code></pre>
</div>

<p>and inside of our <code class="highlighter-rouge">caddy.service</code> file we will paste this …</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[Unit]
Description=Caddy HTTP/2 web server
Documentation=https://caddyserver.com/docs
After=network-online.target
Wants=network-online.target systemd-networkd-wait-online.service

[Service]
Restart=on-failure
StartLimitInterval=86400
StartLimitBurst=5

; User and group the process will run as.
User=www-data
Group=www-data

; Letsencrypt-issued certificates will be written to this directory.
Environment=CADDYPATH=/etc/ssl/caddy

; Always set "-root" to something safe in case it gets forgotten in the Caddyfile.
ExecStart=/usr/local/bin/caddy -log stdout -agree=true -conf=/etc/caddy/Caddyfile -root=/var/tmp
ExecReload=/bin/kill -USR1 $MAINPID

; Limit the number of file descriptors; see `man systemd.exec` for more limit settings.
LimitNOFILE=1048576
; Unmodified caddy is not expected to use more than that.
LimitNPROC=64

; Use private /tmp and /var/tmp, which are discarded after caddy stops.
PrivateTmp=true
; Use a minimal /dev
PrivateDevices=true
; Hide /home, /root, and /run/user. Nobody will steal your SSH-keys.
ProtectHome=true
; Make /usr, /boot, /etc and possibly some more folders read-only.
ProtectSystem=full
; … except /etc/ssl/caddy, because we want Letsencrypt-certificates there.
;   This merely retains r/w access rights, it does not add any new. Must still be writable on the host!
ReadWriteDirectories=/etc/ssl/caddy

; The following additional security directives only work with systemd v229 or later.
; They further retrict privileges that can be gained by caddy. Uncomment if you like.
; Note that you may have to add capabilities required by any plugins in use.
;CapabilityBoundingSet=CAP_NET_BIND_SERVICE
;AmbientCapabilities=CAP_NET_BIND_SERVICE
;NoNewPrivileges=true

[Install]
WantedBy=multi-user.target
</code></pre>
</div>

<p>A couple things to note when we are looking at that configuration file - we are going to store our SSL certificates inside of the <code class="highlighter-rouge">/etc/ssl/caddy</code> directory. <strong>Make sure you keep these certificates secure and backed up.</strong></p>

<p>Caddy will auto detect when our certificates need to be renewed but we must make sure we do keep them secure from people.</p>

<h2 id="onto-the-magic">Onto the Magic</h2>

<p><strong>A quick note:</strong> make sure inside of your <strong>Jenkins &gt; Configure System</strong> you setup your <code class="highlighter-rouge">Jenkins URL</code> to the “<em>https</em>” version of your domains. So for us it will be “<em>https://jenkins.jt.codes</em>”.</p>

<p><strong>NOTE:</strong> make sure to add the “s” after “http” – this will through reverse proxy issues with the Jenkins application.</p>

<p>We are going to copy our <code class="highlighter-rouge">caddy.service</code> file to the <code class="highlighter-rouge">system</code> directory, establish proper ownership/permissions and start out Caddy service.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo cp caddy.service /etc/systemd/system/
sudo chown root:root /etc/systemd/system/caddy.service
sudo chmod 744 /etc/systemd/system/caddy.service
sudo systemctl daemon-reload
sudo systemctl start caddy.service
</code></pre>
</div>

<p>To allow for the Caddy service to start on reboot we can <code class="highlighter-rouge">enable</code> it.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>sudo systemctl <span class="nb">enable </span>caddy.service
</code></pre>
</div>

<p>The service works just like any other <code class="highlighter-rouge">systemd</code> service and we can <strong>start, restart, and stop</strong> - along with seeing the status of the running service with <strong>status</strong>.</p>

<h2 id="going-forward">Going Forward</h2>

<p>Once you verified and established that your Jenkins server is now SSL encrypted - you can dance around for a second. I must say Caddy has been a huge savior when it comes to getting an application out there and secured properly. You can find Caddy on github @ <a href="https://github.com/mholt/caddy">Caddy</a> or <a href="https://github.com/caddyserver">caddyserver</a>’s Organization.</p>

<p>HUGE S/o to <a href="https://github.com/mholt">Matt Holt</a> for doing some amazing things and creating this awesome tech.</p>

<p>I will put out more examples and resources on Caddy, the ACME protocol and how to use Caddy with other types of applications.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Python & VS Code</title>
	  <link>//Settings-Up-Python-Environment-VS-Code</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-01-18T05:00:00+00:00</pubDate>
	  <guid>//Settings-Up-Python-Environment-VS-Code</guid>
	  <description><![CDATA[
	     <h3 id="working-with-vs-code">Working With VS Code</h3>

<p>There are a lot of IDE/Editors out there for Python and I keep getting asked from colleages about how I setup my environment locally. Instead of trying to chain emails, slack/rocketchat each other with long conversations this article will help solve some problems.</p>

<p>VS Code is a fantastic editor that I have been using full-time for about 6 months now (converted from Sublime). I have also used PyCharm and Atom with Python projects and I do think they are viable options as well, but I always end up back with VS Code no matter how hard I try to force myself out of it. I think the flexibility I have with VS Code to develop all types of applications in one place is where I fell in love. I use it for Go, Python, PHP, JavaScript and Scala projects so far.</p>

<p>On to the setup…</p>

<h3 id="setup">Setup</h3>

<p>The biggest thing I try and promote with Python and projects are <strong>virtual environments</strong>. They provide developers the flexibility to have many different Python versions specific to an application. Another promotion I have for Python is <strong>Python 3 – use it</strong>… don’t stray from it. I don’t advocate for people to develop anything in <strong>legacy</strong> Python (2.7). Python 2.7 is so slow that Google even compiles their Python 2.7 code to Go to improve performance <a href="https://github.com/google/grumpy">grumpy</a>. Python 3 fixes a ton of the performance problems that come up in 2.7 – use Python 3!</p>

<p>When you are first setting up your Python project setup your virtualenv with a tool like <strong>pyvenv</strong> … in your trusty <em>Terminal</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="c"># "env" will be the directory that your local dependencies will be install under`</span>
<span class="gp">$ </span>pyvenv env
<span class="c"># this will activate your virtualenv`</span>
<span class="gp">$ </span><span class="nb">source </span>env/bin/activate
<span class="c"># You should see (env) at the beginning of the line in your terminal session now.</span>
</code></pre>
</div>

<p>It’s best practice to have all of your dependencies stored in a file named <code class="highlighter-rouge">requirements.txt</code> at the root of your project’s structure. Here is a sample <em>requirements.txt</em> file with production dependencies I have for a small flask application. Yours obviously will have different dependencies depending on the Python packages you need for you application.</p>

<p><em>requirements.txt</em></p>

<div class="highlighter-rouge"><pre class="highlight"><code># Everything needed in production

wheel

# Flask
Flask
Flask-RESTful
blinker

# Database
Flask-SQLAlchemy
psycopg2
GeoAlchemy2

# Migrations
Flask-Migrate

# Deployment
gunicorn
gevent

# Utils
simplejson
</code></pre>
</div>

<p>To install all these dependencies we just do a simple <code class="highlighter-rouge">pip install -r requirements.txt</code> <strong>BUT</strong> we also need to make sure we have our project’s virtual environment activated before we do the installation.</p>

<p>Your dependencies will be install in that <strong>env</strong> directory and we can locate them if we want to just by looking through the <code class="highlighter-rouge">env/lib/python3.x/site-packages</code> directory. On to the VS Code integration ==» WOO.</p>

<h3 id="vs-code">VS Code</h3>

<p>The first thing you will need to install is a extension called <a href="https://marketplace.visualstudio.com/items?itemName=donjayamanne.python">Python</a>. You can install it with the extension panel on the left side navigation (last button on the bottom). And search for Python – it’s the most downloaded extension when you search for Python. You can read through the docs on that extension to do more custom things but here are the main settings you will need to paste in your <strong>Workplace Settings/User Settings</strong> under your <strong>Preferences</strong>.</p>

<pre><code class="language-JavaScript">// Python specific
"python.pythonPath": "${workspaceRoot}/env/bin/python3.6",
"python.autoComplete.extraPaths": [
    "${workspaceRoot}/env/lib/python3.6/site-packages"
],
"python.devOptions": [
    "DEBUG"
],
"python.linting.pylintEnabled": true,
"python.linting.flake8Enabled": false,
"python.linting.pylintArgs": "pylint --load-plugins pylint-flask",
"python.formatting.provider": "autopep8",
"python.unitTest.unittestEnabled": false,
"python.unitTest.pyTestEnabled": false,
"python.unitTest.nosetestsEnabled": false,
</code></pre>

<p>Paste that into your <strong>settings.json</strong> file that will come up when you select <strong>User Settings</strong> or <strong>Workplace Settings</strong>. The <strong>KEY</strong> to those settings is the “python.pythonPath” and “python.autoComplete.extraPaths” you have to point that to the <em>Path</em> you have to your local virtual environment folders. Also! I will recommend you keep project settings specific to your <strong>Workplace Settings</strong> because you might have many different Python versions when going from project to project and keeping the <strong>User Settings</strong> might break the paths.</p>

<p>There are some custom settings like the linting/testings you can do inside of the editor as well. I tend to stick with my terminal to run external things like that but you can play around with it – this should give you the basic VS Code environment for developing with Python.</p>

	  ]]></description>
	</item>

	<item>
	  <title>Twenty-Sixteen</title>
	  <link>//Twenty-Sixteen</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2017-01-03T05:00:00+00:00</pubDate>
	  <guid>//Twenty-Sixteen</guid>
	  <description><![CDATA[
	     <h3 id="in-review">2016 in Review</h3>

<p>Twenty-sixteen was definitely a year to remember. I constantly look back thinking about all the things that changed in my life from graduating from undergrad, finishing my baseball career, to pushing production code the first day on the job, leading and contributing to some fantastic applications within the State Department… it’s been a crazy year.</p>

<p>When it comes to growing in my technology life I was so back and forth with languages. When I first came out of college I had a ton of experience with PHP and Java so obviously I loved what I knew. Little did I start leaning towards the more “hip” languages like Node and JavaScript.  I was the typical JS fanboy (and still am) but it was a complete change in mindset of how concurrency worked without having to architect major multi threaded applications.  To say the least it was a hit.  I got to enjoy the great complexities of the JavaScript language at it’s finest using it in the frontend with ReactJS and also on the server side.</p>

<p>But then, I decided to look into Python because it wasn’t new and it was a solid language that people have been developing with for year.  It was hitting a soft spot in my heart because it really was so simple and easy for me to take all the CS concepts I already knew and apply them super easy and fast with a scripting language.  I could iterate on applications pretty fast without having to handle JavaScript callbacks with promises and async/await.  I fell in love with it I could also do some awesome machine learning odds and ends with packages like numpy, scikit-learn, etc.  The biggest thing I missed from Node was the concurrency though - as much as a pain callbacks were to wrap my head around at first.  Enter the room… Go.</p>

<p>I don’t really remember how Golang (“Go”) was introduced to me but I must say it’s been an adventure to say the least.  The community around Go is growing more and more everyday - not many people really understand how powerful Go can be.  I love the concurrency model - no more promises and callback pyramids you get thrown into like you did in JavaScript; there aren’t crazy multiple threading issues you run into like in Java.  The magic is in the CSP-Model (Communicating Sequential Processes) – you have these channels that bridge messages sent between “goroutines” that are running concurrent processes.  You wait and block while messages are getting sent through these “channels” it’s a beautiful and simple complexity once you understand how powerful they can be.  There are so many amazing things that are being built in Go - it seems that the future of distributed systems and development is being written in Go.  The big players in the tech business are using it and backing it – Uber, DropBox, Docker, DigitalOcean, and many more… oh and Google (they made/maintain it).</p>

<p>Learning more about all things technology is my passion I couldn’t have imagined how much I’ve learned since starting my professional career but it’s been fantastic so far and I can’t wait for the next year’s challenges!  Polyglot is the best mentality I have – I think the best builders use all their tools to their best abilities.  Having a strong base of many languages is at the core of what I think it means to be a software engineer.</p>

<h4 id="the-year-to-come">The Year to Come</h4>

<p>Top things to do in 2017</p>

<ul>
  <li>Expand more on containers and container orchestration (Docker + Kubernetes?)</li>
  <li>More open source development…currently none :(</li>
  <li>Look into open source projects…per previous TODO</li>
  <li>Expand on more ReactJS applications (or insert favorite JS Framework)</li>
  <li>Get more into “non” SQL based databases
    <ul>
      <li>Previous usage of Elasticsearch and Neo4J</li>
    </ul>
  </li>
  <li>Go, Go, and more Go (learning Go has been awesome so far – keep GOing!)</li>
</ul>

	  ]]></description>
	</item>

	<item>
	  <title>Creating A RESTful API w/ Elasticsearch</title>
	  <link>//Creating-A-RESTful-API-w-Elasticsearch</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2016-12-20T05:00:00+00:00</pubDate>
	  <guid>//Creating-A-RESTful-API-w-Elasticsearch</guid>
	  <description><![CDATA[
	     <h4 id="in-progress">(In Progress)</h4>

<h3 id="objective">Objective:</h3>
<p>We want to establish a way to query <em><strong>Elasticsearch</strong></em> through a RESTful API’s endpoints.</p>

<h3 id="pre-requirements">Pre-Requirements</h3>

<ul>
  <li>Python 3+
    <ul>
      <li>Knowledge of virtual environments, dependency management with <strong>PIP</strong></li>
    </ul>
  </li>
  <li>Elasticsearch 2.X
    <ul>
      <li>Install Elasticseach on Centos 7 –&gt; <a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-configure-elasticsearch-on-centos-7">es-on-centos-7</a></li>
      <li><a href="https://www.elastic.co/products/elasticsearch">Elasticsearch</a></li>
    </ul>
  </li>
</ul>

<h3 id="wsgi-application-flask">WSGI Application (Flask)</h3>

<p>We are going to be using the micro-framework, <em>flask</em>, in this tutorial.  We will use the <em>elasticsearch-dsl-py</em> package that elastic created to interact with elasticsearch at a more high level abstraction.</p>

<h4 id="project-structure">Project Structure</h4>

<div class="highlighter-rouge"><pre class="highlight"><code>.
├── app/
│   ├── index.md
│   ├── api/
│   │   ├── __init__.py
│   │   ├── resources/
│   │   │   ├── __init__.py
│   │   │   ├── search.py
│   │   ├── search_config/
│   │   │   ├── __init__.py
│   ├── __init__.py
│   ├── config.py
│   ├── extensions.py
│   ├── helpers.py
├── env/
├── requirements/
│   ├── development.txt
│   ├── production.txt
├── tests/
│   ├── unit/
│   │   ├── test_*.py
│   ├── __init__.py
│   ├── conftest.py
├── manage.py
├── requirements.txt
├── runtime.txt
├── setup.cfg
</code></pre>
</div>

<p>To be continued…</p>

	  ]]></description>
	</item>

	<item>
	  <title>Elasticsearch Info/Resources</title>
	  <link>//Elasticsearch</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2016-12-13T05:00:00+00:00</pubDate>
	  <guid>//Elasticsearch</guid>
	  <description><![CDATA[
	     <p>Elasticsearch is a “NRT” (Near Real Time) search platform which means the data that is being ingested is nearly searchable within &lt; 1 second.</p>

<h2 id="basic-concepts">Basic Concepts</h2>

<p>You can learn more about Elasticsearch and it’s basic concepts at their <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html">docs</a></p>

<h5 id="cluster">Cluster</h5>
<p>The cluster concept in ES is that you can have a bunch of nodes (or servers) that hold all your data together.</p>

<h5 id="node">Node</h5>
<p>A node is a single elasticsearch server (or service) that is running holding a collection of indexes and data regarding each index.</p>

<h5 id="index">Index</h5>
<p>An index is thought of as a “database” in relational terms. It is a higher level concept that can be thought of as similar characteristics for the document data.</p>

<h5 id="type">Type</h5>
<p>Types can be thought of as “tables” in relational terms. It is a more definied catagorization of data for each document stored in ES.
One way to think about it is you have a higher level index of “User Data” and you can have “Order Data”, “Comment Data”, etc.</p>

<h5 id="document">Document</h5>
<p>These are the lowest level catagorization of document data in ES. Think of these as “rows” in a relational mindset.  You can have attributes in each document that describe the data’s features.</p>

<h5 id="shardingreplication">Sharding/Replication</h5>
<p>We can do multiple sharding instances on indexes if we are storing huge amount of document data in them. <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/_basic_concepts.html#_shards_amp_replicas">Sharding</a></p>

<h2 id="resources">Resources</h2>

<h3 id="elasticsearch">Elasticsearch</h3>
<ul>
  <li><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html">Quick Reference</a></li>
</ul>

<h3 id="elasticseach-language-specific">Elasticseach (language specific)</h3>
<ul>
  <li><a href="http://elasticsearch-dsl.readthedocs.io/en/latest/">elasticsearch-dsl</a></li>
  <li><a href="http://elasticsearch-py.readthedocs.io/en/master/">elasticsearch-py</a></li>
  <li><a href="https://www.elastic.co/products/elasticsearch">elasticsearch</a></li>
  <li><a href="https://olivere.github.io/elastic/">elastic</a></li>
  <li><a href="https://godoc.org/gopkg.in/olivere/elastic.v3">more elastic</a></li>
</ul>

<h3 id="external-backend-frameworks">External Backend Frameworks</h3>
<ul>
  <li><a href="http://flask.pocoo.org/">flask</a></li>
  <li><a href="http://flask-restful-cn.readthedocs.io/en/0.3.5/">flask-restful</a></li>
  <li><a href="https://gin-gonic.github.io/gin/">gin</a></li>
</ul>

<h3 id="small-examples">Small Examples</h3>
<ul>
  <li><a href="https://github.com/jtaylor32/elasticsearch-restful-api">rest-api</a></li>
  <li><a href="https://github.com/jtaylor32/elasticsearch-bulk-ingestion">bulk-ingestion</a></li>
</ul>

<h3 id="web-scrapers">Web Scrapers</h3>
<ul>
  <li><a href="http://nutch.apache.org/">nutch</a></li>
  <li><a href="https://scrapy.org/">scrapy</a></li>
  <li><a href="https://github.com/yhat/scrape">scrape</a></li>
</ul>

<h3 id="blogsbooks">Blogs/Books</h3>
<ul>
  <li><a href="http://docs.python-guide.org/en/latest/scenarios/scrape/">python-scraping</a></li>
  <li><a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/">more-python-scraping</a></li>
  <li><a href="https://schier.co/blog/2015/04/26/a-simple-web-scraper-in-go.html">go-scraping</a></li>
  <li><a href="http://shop.oreilly.com/product/0636920034391.do">Web Scraping with Python</a></li>
  <li><a href="https://qbox.io/blog/scraping-the-web-with-nutch-for-elasticsearch">Scraping with Nutch</a></li>
</ul>

<h3 id="other-es-articles">Other ES Articles</h3>
<ul>
  <li><a href="http://goinbigdata.com/working-with-elasticsearch-in-go/">es-in-go</a></li>
  <li><a href="http://126kr.com/article/5c4jgpiwtwp">testing-go-es</a></li>
  <li><a href="https://msftstack.wordpress.com/2016/02/18/making-a-book-search-engine-in-python-and-elasticsearch/">python-with-es</a></li>
  <li>more to come…</li>
</ul>

<p>continued…</p>

	  ]]></description>
	</item>

	<item>
	  <title>Creating Master Slave Replication in MySQL on CentOS 7</title>
	  <link>//Creating-Master-Slave-replication-in-MySQL-56-on-CentOS-7</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2016-09-30T05:00:00+00:00</pubDate>
	  <guid>//Creating-Master-Slave-replication-in-MySQL-56-on-CentOS-7</guid>
	  <description><![CDATA[
	     <h3 id="master-server">Master Server</h3>

<p>Edit the my.cnf</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo vi /etc/my.cnf
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>server-id = 1
binlog_do_db = testdatabase
relay-log = mysql-relay-bin
relay-log-index = mysql-relay-bin.index
log_bin = mysql-bin.log
</code></pre>
</div>

<p>Restart mysqld</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo systemctl restart mysqld
</code></pre>
</div>

<p>In mysql</p>

<p><code class="highlighter-rouge">mysql -u root -p</code></p>

<div class="highlighter-rouge"><pre class="highlight"><code>-- create a database to replicate
&gt; CREATE DATABASE testdatabase;
&gt; USE testdatabase;
-- create a table in testdatabase
&gt; CREATE TABLE Users (name varchar(30), age INT);
-- insert data
&gt; INSERT INTO testdatabase.Users Values ('Test Name', 1);
&gt; INSERT INTO testdatabase.Users Values ('Test Name', 2);

--
&gt; GRANT REPLICATION SLAVE ON *.* TO 'slaveuser'@'%' IDENTIFIED BY 'PASSWORD'
&gt; FLUSH PRIVILEGES;
&gt; FLUSH TABLES WITH READ LOCK;
&gt; SHOW MASTER STATUS;

+------------------+----------+--------------+------------------+-------------------+
| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |
+------------------+----------+--------------+------------------+-------------------+
| mysql-bin.000001 |     101 | testdatabase |                  |                   |
+------------------+----------+--------------+------------------+-------------------+
1 row in set (0.00 sec)
</code></pre>
</div>

<p>Make sure the ‘PASSWORD’ is <strong>secure</strong></p>

<p>Do a backup to transfer to the slave server</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>mysqldump -u root -p --master-data testdatabase &gt; /home/centos/database.sql
</code></pre>
</div>

<p>Move it to the slave server</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>rsync -Waq -e ssh /home/centos/database.sql centos@IPADDRESS:/home/centos/
</code></pre>
</div>

<p>IPADDRESS is the slave IP</p>

<h3 id="on-slave-server">On Slave Server</h3>

<p>Update the my.cnf file</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo vi /etc/my.cnf
</code></pre>
</div>

<p>Add this to the file</p>

<div class="highlighter-rouge"><pre class="highlight"><code>server-id = 2
</code></pre>
</div>

<p>Restart mysqld.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo systemctl restart mysqld
</code></pre>
</div>

<p>Import the database</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>mysql -u root -p testdatabase &lt; /home/centos/database.sql
</code></pre>
</div>

<p>Note. you must have the database ‘testdatabase’ created.</p>

<p>In mysql shell(<code class="highlighter-rouge">mysql -u root -p</code>)</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mysql&gt; STOP SLAVE;
mysql&gt; CHANGE MASTER TO
  -&gt;  MASTER_HOST='host-name',
  -&gt;  MASTER_USER='slaveuser',
  -&gt;  MASTER_PASSWORD='PASSWORD',
  -&gt;  MASTER_LOG_FILE='log file from the MASTER STATUS',
  -&gt;  MASTER_LOG_POS=(postion from MASTER STATUS);
mysql&gt; START SLAVE;
mysql&gt; SHOW SLAVE STATUS;
</code></pre>
</div>

<p>After this to test it insert some data in the master database and select * from both to check consistency.</p>

<p>Cheers!</p>

	  ]]></description>
	</item>

	<item>
	  <title>Installing MySQL 5.6 on CentOS 7</title>
	  <link>//Installing-MySQL-56-on-CentOS-7</link>
	  <author>Jordan Taylor</author>
	  <pubDate>2016-09-29T05:00:00+00:00</pubDate>
	  <guid>//Installing-MySQL-56-on-CentOS-7</guid>
	  <description><![CDATA[
	     <h3 id="download-the-mysql-yum-repository">Download the MySQL Yum Repository</h3>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo yum install http://dev.mysql.com/get/mysql57-community-release-el7-9.noarch.rpm
</code></pre>
</div>

<p>We don’t want MySQL version <em>5.7</em> enabled, we want <em>5.6</em>, so we must go alter the configuration file. You should only enable subrepository for one release series at any time. When subrepositories for more than one release series are enabled, the latest series will be used by Yum.</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo vi /etc/yum.repos.d/mysql-community.repo
</code></pre>
</div>

<p>Then alter the file to say :</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  <span class="c"># Enable to use MySQL 5.6</span>
  <span class="o">[</span>mysql56-community]
  <span class="nv">name</span><span class="o">=</span>MySQL 5.6 Community Server
  <span class="nv">baseurl</span><span class="o">=</span>http://repo.mysql.com/yum/mysql-5.6-community/el/7/<span class="nv">$basearch</span>/
  <span class="nv">enabled</span><span class="o">=</span>1
  <span class="nv">gpgcheck</span><span class="o">=</span>1
  <span class="nv">gpgkey</span><span class="o">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql

  <span class="o">[</span>mysql57-community]
  <span class="nv">name</span><span class="o">=</span>MySQL 5.7 Community Server
  <span class="nv">baseurl</span><span class="o">=</span>http://repo.mysql.com/yum/mysql-5.7-community/el/7/<span class="nv">$basearch</span>/
  <span class="nv">enabled</span><span class="o">=</span>0
  <span class="nv">gpgcheck</span><span class="o">=</span>1
  <span class="nv">gpgkey</span><span class="o">=</span>file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql
</code></pre>
</div>

<p>Enable and show the running repository with :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo yum repolist enabled | grep <span class="s2">"mysql.*-community.*"</span>
</code></pre>
</div>

<p>This should show…</p>

<div class="highlighter-rouge"><pre class="highlight"><code>mysql-connectors-community/x86_64       MySQL Connectors Community           21
mysql-tools-community/x86_64            MySQL Tools Community                36
mysql57-community/x86_64                MySQL 5.6 Community Server          128
</code></pre>
</div>

<p>After you alter the configuration file and enable the repolist you can show the full list :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>yum repolist all | grep mysql
</code></pre>
</div>

<h3 id="install-mysql">Install MySQL</h3>

<p>Install MySQL with the following command :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo yum install mysql-community-server
</code></pre>
</div>

<p>Output:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Loaded plugins: fastestmirror
mysql-connectors-community                                                            | 2.5 kB  00:00:00
mysql-tools-community                                                                 | 2.5 kB  00:00:00
mysql56-community                                                                     | 2.5 kB  00:00:00
mysql56-community/x86_64/primary_db                                                   | 146 kB  00:00:00
Loading mirror speeds from cached hostfile
* base: mirror.cogentco.com
* extras: mirror.atlanticmetro.net
* updates: mirrors.greenmountainaccess.net
Resolving Dependencies
--&gt; Running transaction check
---&gt; Package mysql-community-server.x86_64 0:5.6.33-2.el7 will be installed
--&gt; Processing Dependency: mysql-community-common(x86-64) = 5.6.33-2.el7 for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: mysql-community-client(x86-64) &gt;= 5.6.10 for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(warnings) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(strict) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(if) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(Sys::Hostname) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(POSIX) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(Getopt::Long) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(File::Temp) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(File::Spec) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(File::Path) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(File::Copy) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(File::Basename) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(Fcntl) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(Data::Dumper) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(DBI) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: libaio.so.1(LIBAIO_0.4)(64bit) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: libaio.so.1(LIBAIO_0.1)(64bit) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: /usr/bin/perl for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: libaio.so.1()(64bit) for package: mysql-community-server-5.6.33-2.el7.x86_64
--&gt; Running transaction check
---&gt; Package libaio.x86_64 0:0.3.109-13.el7 will be installed
---&gt; Package mysql-community-client.x86_64 0:5.6.33-2.el7 will be installed
--&gt; Processing Dependency: mysql-community-libs(x86-64) &gt;= 5.6.10 for package: mysql-community-client-5.6.33-2.el7.x86_64
--&gt; Processing Dependency: perl(Exporter) for package: mysql-community-client-5.6.33-2.el7.x86_64
---&gt; Package mysql-community-common.x86_64 0:5.6.33-2.el7 will be installed
---&gt; Package perl.x86_64 4:5.16.3-286.el7 will be installed
--&gt; Processing Dependency: perl-libs = 4:5.16.3-286.el7 for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Socket) &gt;= 1.3 for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Scalar::Util) &gt;= 1.10 for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl-macros for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl-libs for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(threads::shared) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(threads) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(constant) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Time::Local) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Time::HiRes) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Storable) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Socket) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Scalar::Util) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Pod::Simple::XHTML) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Pod::Simple::Search) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Filter::Util::Call) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: perl(Carp) for package: 4:perl-5.16.3-286.el7.x86_64
--&gt; Processing Dependency: libperl.so()(64bit) for package: 4:perl-5.16.3-286.el7.x86_64
---&gt; Package perl-DBI.x86_64 0:1.627-4.el7 will be installed
--&gt; Processing Dependency: perl(RPC::PlServer) &gt;= 0.2001 for package: perl-DBI-1.627-4.el7.x86_64
--&gt; Processing Dependency: perl(RPC::PlClient) &gt;= 0.2000 for package: perl-DBI-1.627-4.el7.x86_64
---&gt; Package perl-Data-Dumper.x86_64 0:2.145-3.el7 will be installed
---&gt; Package perl-File-Path.noarch 0:2.09-2.el7 will be installed
---&gt; Package perl-File-Temp.noarch 0:0.23.01-3.el7 will be installed
---&gt; Package perl-Getopt-Long.noarch 0:2.40-2.el7 will be installed
--&gt; Processing Dependency: perl(Pod::Usage) &gt;= 1.14 for package: perl-Getopt-Long-2.40-2.el7.noarch
--&gt; Processing Dependency: perl(Text::ParseWords) for package: perl-Getopt-Long-2.40-2.el7.noarch
---&gt; Package perl-PathTools.x86_64 0:3.40-5.el7 will be installed
--&gt; Running transaction check
---&gt; Package mariadb-libs.x86_64 1:5.5.50-1.el7_2 will be obsoleted
---&gt; Package mysql-community-libs.x86_64 0:5.6.33-2.el7 will be obsoleting
---&gt; Package perl-Carp.noarch 0:1.26-244.el7 will be installed
---&gt; Package perl-Exporter.noarch 0:5.68-3.el7 will be installed
---&gt; Package perl-Filter.x86_64 0:1.49-3.el7 will be installed
---&gt; Package perl-PlRPC.noarch 0:0.2020-14.el7 will be installed
--&gt; Processing Dependency: perl(Net::Daemon) &gt;= 0.13 for package: perl-PlRPC-0.2020-14.el7.noarch
--&gt; Processing Dependency: perl(Net::Daemon::Test) for package: perl-PlRPC-0.2020-14.el7.noarch
--&gt; Processing Dependency: perl(Net::Daemon::Log) for package: perl-PlRPC-0.2020-14.el7.noarch
--&gt; Processing Dependency: perl(Compress::Zlib) for package: perl-PlRPC-0.2020-14.el7.noarch
---&gt; Package perl-Pod-Simple.noarch 1:3.28-4.el7 will be installed
--&gt; Processing Dependency: perl(Pod::Escapes) &gt;= 1.04 for package: 1:perl-Pod-Simple-3.28-4.el7.noarch
--&gt; Processing Dependency: perl(Encode) for package: 1:perl-Pod-Simple-3.28-4.el7.noarch
---&gt; Package perl-Pod-Usage.noarch 0:1.63-3.el7 will be installed
--&gt; Processing Dependency: perl(Pod::Text) &gt;= 3.15 for package: perl-Pod-Usage-1.63-3.el7.noarch
--&gt; Processing Dependency: perl-Pod-Perldoc for package: perl-Pod-Usage-1.63-3.el7.noarch
---&gt; Package perl-Scalar-List-Utils.x86_64 0:1.27-248.el7 will be installed
---&gt; Package perl-Socket.x86_64 0:2.010-3.el7 will be installed
---&gt; Package perl-Storable.x86_64 0:2.45-3.el7 will be installed
---&gt; Package perl-Text-ParseWords.noarch 0:3.29-4.el7 will be installed
---&gt; Package perl-Time-HiRes.x86_64 4:1.9725-3.el7 will be installed
---&gt; Package perl-Time-Local.noarch 0:1.2300-2.el7 will be installed
---&gt; Package perl-constant.noarch 0:1.27-2.el7 will be installed
---&gt; Package perl-libs.x86_64 4:5.16.3-286.el7 will be installed
---&gt; Package perl-macros.x86_64 4:5.16.3-286.el7 will be installed
---&gt; Package perl-threads.x86_64 0:1.87-4.el7 will be installed
---&gt; Package perl-threads-shared.x86_64 0:1.43-6.el7 will be installed
--&gt; Running transaction check
---&gt; Package perl-Encode.x86_64 0:2.51-7.el7 will be installed
---&gt; Package perl-IO-Compress.noarch 0:2.061-2.el7 will be installed
--&gt; Processing Dependency: perl(Compress::Raw::Zlib) &gt;= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch
--&gt; Processing Dependency: perl(Compress::Raw::Bzip2) &gt;= 2.061 for package: perl-IO-Compress-2.061-2.el7.noarch
---&gt; Package perl-Net-Daemon.noarch 0:0.48-5.el7 will be installed
---&gt; Package perl-Pod-Escapes.noarch 1:1.04-286.el7 will be installed
---&gt; Package perl-Pod-Perldoc.noarch 0:3.20-4.el7 will be installed
--&gt; Processing Dependency: perl(parent) for package: perl-Pod-Perldoc-3.20-4.el7.noarch
--&gt; Processing Dependency: perl(HTTP::Tiny) for package: perl-Pod-Perldoc-3.20-4.el7.noarch
---&gt; Package perl-podlators.noarch 0:2.5.1-3.el7 will be installed
--&gt; Running transaction check
---&gt; Package perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7 will be installed
---&gt; Package perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7 will be installed
---&gt; Package perl-HTTP-Tiny.noarch 0:0.033-3.el7 will be installed
---&gt; Package perl-parent.noarch 1:0.225-244.el7 will be installed
--&gt; Finished Dependency Resolution

Dependencies Resolved

=============================================================================================================
Package                          Arch            Version                   Repository                  Size
=============================================================================================================
Installing:
mysql-community-libs             x86_64          5.6.33-2.el7              mysql56-community          2.0 M
    replacing  mariadb-libs.x86_64 1:5.5.50-1.el7_2
mysql-community-server           x86_64          5.6.33-2.el7              mysql56-community           59 M
Installing for dependencies:
libaio                           x86_64          0.3.109-13.el7            base                        24 k
mysql-community-client           x86_64          5.6.33-2.el7              mysql56-community           19 M
mysql-community-common           x86_64          5.6.33-2.el7              mysql56-community          256 k
perl                             x86_64          4:5.16.3-286.el7          base                       8.0 M
perl-Carp                        noarch          1.26-244.el7              base                        19 k
perl-Compress-Raw-Bzip2          x86_64          2.061-3.el7               base                        32 k
perl-Compress-Raw-Zlib           x86_64          1:2.061-4.el7             base                        57 k
perl-DBI                         x86_64          1.627-4.el7               base                       802 k
perl-Data-Dumper                 x86_64          2.145-3.el7               base                        47 k
perl-Encode                      x86_64          2.51-7.el7                base                       1.5 M
perl-Exporter                    noarch          5.68-3.el7                base                        28 k
perl-File-Path                   noarch          2.09-2.el7                base                        26 k
perl-File-Temp                   noarch          0.23.01-3.el7             base                        56 k
perl-Filter                      x86_64          1.49-3.el7                base                        76 k
perl-Getopt-Long                 noarch          2.40-2.el7                base                        56 k
perl-HTTP-Tiny                   noarch          0.033-3.el7               base                        38 k
perl-IO-Compress                 noarch          2.061-2.el7               base                       260 k
perl-Net-Daemon                  noarch          0.48-5.el7                base                        51 k
perl-PathTools                   x86_64          3.40-5.el7                base                        82 k
perl-PlRPC                       noarch          0.2020-14.el7             base                        36 k
perl-Pod-Escapes                 noarch          1:1.04-286.el7            base                        50 k
perl-Pod-Perldoc                 noarch          3.20-4.el7                base                        87 k
perl-Pod-Simple                  noarch          1:3.28-4.el7              base                       216 k
perl-Pod-Usage                   noarch          1.63-3.el7                base                        27 k
perl-Scalar-List-Utils           x86_64          1.27-248.el7              base                        36 k
perl-Socket                      x86_64          2.010-3.el7               base                        49 k
perl-Storable                    x86_64          2.45-3.el7                base                        77 k
perl-Text-ParseWords             noarch          3.29-4.el7                base                        14 k
perl-Time-HiRes                  x86_64          4:1.9725-3.el7            base                        45 k
perl-Time-Local                  noarch          1.2300-2.el7              base                        24 k
perl-constant                    noarch          1.27-2.el7                base                        19 k
perl-libs                        x86_64          4:5.16.3-286.el7          base                       687 k
perl-macros                      x86_64          4:5.16.3-286.el7          base                        43 k
perl-parent                      noarch          1:0.225-244.el7           base                        12 k
perl-podlators                   noarch          2.5.1-3.el7               base                       112 k
perl-threads                     x86_64          1.87-4.el7                base                        49 k
perl-threads-shared              x86_64          1.43-6.el7                base                        39 k

Transaction Summary
=============================================================================================================
Install  2 Packages (+37 Dependent packages)

Total download size: 93 M
Is this ok [y/d/N]: y
Downloading packages:
warning: /var/cache/yum/x86_64/7/mysql56-community/packages/mysql-community-common-5.6.33-2.el7.x86_64.rpm: Header V3 DSA/SHA1 Signature, key ID 5072e1f5: NOKEY
Public key for mysql-community-common-5.6.33-2.el7.x86_64.rpm is not installed
(1/39): mysql-community-common-5.6.33-2.el7.x86_64.rpm                                | 256 kB  00:00:00
(2/39): mysql-community-libs-5.6.33-2.el7.x86_64.rpm                                  | 2.0 MB  00:00:00
(3/39): libaio-0.3.109-13.el7.x86_64.rpm                                              |  24 kB  00:00:00
(4/39): perl-Carp-1.26-244.el7.noarch.rpm                                             |  19 kB  00:00:00
(5/39): perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64.rpm                                |  32 kB  00:00:00
(6/39): perl-Compress-Raw-Zlib-2.061-4.el7.x86_64.rpm                                 |  57 kB  00:00:00
(7/39): mysql-community-client-5.6.33-2.el7.x86_64.rpm                                |  19 MB  00:00:02
(8/39): perl-DBI-1.627-4.el7.x86_64.rpm                                               | 802 kB  00:00:01
(9/39): perl-Data-Dumper-2.145-3.el7.x86_64.rpm                                       |  47 kB  00:00:00
(10/39): perl-Encode-2.51-7.el7.x86_64.rpm                                            | 1.5 MB  00:00:01
(11/39): perl-Exporter-5.68-3.el7.noarch.rpm                                          |  28 kB  00:00:00
(12/39): perl-File-Path-2.09-2.el7.noarch.rpm                                         |  26 kB  00:00:00
(13/39): mysql-community-server-5.6.33-2.el7.x86_64.rpm                               |  59 MB  00:00:04
(14/39): perl-File-Temp-0.23.01-3.el7.noarch.rpm                                      |  56 kB  00:00:00
(15/39): perl-5.16.3-286.el7.x86_64.rpm                                               | 8.0 MB  00:00:04
(16/39): perl-Filter-1.49-3.el7.x86_64.rpm                                            |  76 kB  00:00:00
(17/39): perl-HTTP-Tiny-0.033-3.el7.noarch.rpm                                        |  38 kB  00:00:00
(18/39): perl-Getopt-Long-2.40-2.el7.noarch.rpm                                       |  56 kB  00:00:00
(19/39): perl-IO-Compress-2.061-2.el7.noarch.rpm                                      | 260 kB  00:00:00
(20/39): perl-Net-Daemon-0.48-5.el7.noarch.rpm                                        |  51 kB  00:00:00
(21/39): perl-PathTools-3.40-5.el7.x86_64.rpm                                         |  82 kB  00:00:00
(22/39): perl-PlRPC-0.2020-14.el7.noarch.rpm                                          |  36 kB  00:00:00
(23/39): perl-Pod-Escapes-1.04-286.el7.noarch.rpm                                     |  50 kB  00:00:00
(24/39): perl-Pod-Perldoc-3.20-4.el7.noarch.rpm                                       |  87 kB  00:00:00
(25/39): perl-Pod-Simple-3.28-4.el7.noarch.rpm                                        | 216 kB  00:00:00
(26/39): perl-Pod-Usage-1.63-3.el7.noarch.rpm                                         |  27 kB  00:00:00
(27/39): perl-Scalar-List-Utils-1.27-248.el7.x86_64.rpm                               |  36 kB  00:00:00
(28/39): perl-Socket-2.010-3.el7.x86_64.rpm                                           |  49 kB  00:00:00
(29/39): perl-Text-ParseWords-3.29-4.el7.noarch.rpm                                   |  14 kB  00:00:00
(30/39): perl-Storable-2.45-3.el7.x86_64.rpm                                          |  77 kB  00:00:00
(31/39): perl-Time-Local-1.2300-2.el7.noarch.rpm                                      |  24 kB  00:00:00
(32/39): perl-Time-HiRes-1.9725-3.el7.x86_64.rpm                                      |  45 kB  00:00:00
(33/39): perl-constant-1.27-2.el7.noarch.rpm                                          |  19 kB  00:00:00
(34/39): perl-macros-5.16.3-286.el7.x86_64.rpm                                        |  43 kB  00:00:00
(35/39): perl-parent-0.225-244.el7.noarch.rpm                                         |  12 kB  00:00:00
(36/39): perl-libs-5.16.3-286.el7.x86_64.rpm                                          | 687 kB  00:00:00
(37/39): perl-podlators-2.5.1-3.el7.noarch.rpm                                        | 112 kB  00:00:00
(38/39): perl-threads-1.87-4.el7.x86_64.rpm                                           |  49 kB  00:00:00
(39/39): perl-threads-shared-1.43-6.el7.x86_64.rpm                                    |  39 kB  00:00:00
-------------------------------------------------------------------------------------------------------------
Total                                                                         14 MB/s |  93 MB  00:00:06
Retrieving key from file:///etc/pki/rpm-gpg/RPM-GPG-KEY-mysql
Importing GPG key 0x5072E1F5:
Userid     : "MySQL Release Engineering &lt;mysql-build@oss.oracle.com&gt;"
Fingerprint: a4a9 4068 76fc bd3c 4567 70c8 8c71 8d3b 5072 e1f5
Package    : mysql57-community-release-el7-9.noarch (@/mysql57-community-release-el7-9.noarch)
From       : /etc/pki/rpm-gpg/RPM-GPG-KEY-mysql
Is this ok [y/N]: y
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : mysql-community-common-5.6.33-2.el7.x86_64                                               1/40
  Installing : mysql-community-libs-5.6.33-2.el7.x86_64                                                 2/40
  Installing : 1:perl-parent-0.225-244.el7.noarch                                                       3/40
  Installing : perl-HTTP-Tiny-0.033-3.el7.noarch                                                        4/40
  Installing : perl-podlators-2.5.1-3.el7.noarch                                                        5/40
  Installing : perl-Pod-Perldoc-3.20-4.el7.noarch                                                       6/40
  Installing : 1:perl-Pod-Escapes-1.04-286.el7.noarch                                                   7/40
  Installing : perl-Text-ParseWords-3.29-4.el7.noarch                                                   8/40
  Installing : perl-Encode-2.51-7.el7.x86_64                                                            9/40
  Installing : perl-Pod-Usage-1.63-3.el7.noarch                                                        10/40
  Installing : 4:perl-libs-5.16.3-286.el7.x86_64                                                       11/40
  Installing : 4:perl-macros-5.16.3-286.el7.x86_64                                                     12/40
  Installing : 4:perl-Time-HiRes-1.9725-3.el7.x86_64                                                   13/40
  Installing : perl-Exporter-5.68-3.el7.noarch                                                         14/40
  Installing : perl-constant-1.27-2.el7.noarch                                                         15/40
  Installing : perl-Time-Local-1.2300-2.el7.noarch                                                     16/40
  Installing : perl-Socket-2.010-3.el7.x86_64                                                          17/40
  Installing : perl-Carp-1.26-244.el7.noarch                                                           18/40
  Installing : perl-PathTools-3.40-5.el7.x86_64                                                        19/40
  Installing : perl-Scalar-List-Utils-1.27-248.el7.x86_64                                              20/40
  Installing : perl-Storable-2.45-3.el7.x86_64                                                         21/40
  Installing : perl-File-Temp-0.23.01-3.el7.noarch                                                     22/40
  Installing : perl-File-Path-2.09-2.el7.noarch                                                        23/40
  Installing : perl-threads-shared-1.43-6.el7.x86_64                                                   24/40
  Installing : perl-threads-1.87-4.el7.x86_64                                                          25/40
  Installing : perl-Filter-1.49-3.el7.x86_64                                                           26/40
  Installing : 1:perl-Pod-Simple-3.28-4.el7.noarch                                                     27/40
  Installing : perl-Getopt-Long-2.40-2.el7.noarch                                                      28/40
  Installing : 4:perl-5.16.3-286.el7.x86_64                                                            29/40
  Installing : perl-Data-Dumper-2.145-3.el7.x86_64                                                     30/40
  Installing : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                                              31/40
  Installing : perl-Net-Daemon-0.48-5.el7.noarch                                                       32/40
  Installing : mysql-community-client-5.6.33-2.el7.x86_64                                              33/40
  Installing : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                                             34/40
  Installing : perl-IO-Compress-2.061-2.el7.noarch                                                     35/40
  Installing : perl-PlRPC-0.2020-14.el7.noarch                                                         36/40
  Installing : perl-DBI-1.627-4.el7.x86_64                                                             37/40
  Installing : libaio-0.3.109-13.el7.x86_64                                                            38/40
  Installing : mysql-community-server-5.6.33-2.el7.x86_64                                              39/40
  Erasing    : 1:mariadb-libs-5.5.50-1.el7_2.x86_64                                                    40/40
  Verifying  : perl-HTTP-Tiny-0.033-3.el7.noarch                                                        1/40
  Verifying  : mysql-community-common-5.6.33-2.el7.x86_64                                               2/40
  Verifying  : perl-threads-shared-1.43-6.el7.x86_64                                                    3/40
  Verifying  : 4:perl-Time-HiRes-1.9725-3.el7.x86_64                                                    4/40
  Verifying  : perl-IO-Compress-2.061-2.el7.noarch                                                      5/40
  Verifying  : perl-Exporter-5.68-3.el7.noarch                                                          6/40
  Verifying  : perl-constant-1.27-2.el7.noarch                                                          7/40
  Verifying  : perl-PathTools-3.40-5.el7.x86_64                                                         8/40
  Verifying  : 4:perl-libs-5.16.3-286.el7.x86_64                                                        9/40
  Verifying  : 4:perl-macros-5.16.3-286.el7.x86_64                                                     10/40
  Verifying  : perl-Compress-Raw-Bzip2-2.061-3.el7.x86_64                                              11/40
  Verifying  : 1:perl-parent-0.225-244.el7.noarch                                                      12/40
  Verifying  : mysql-community-server-5.6.33-2.el7.x86_64                                              13/40
  Verifying  : perl-Net-Daemon-0.48-5.el7.noarch                                                       14/40
  Verifying  : 4:perl-5.16.3-286.el7.x86_64                                                            15/40
  Verifying  : perl-File-Temp-0.23.01-3.el7.noarch                                                     16/40
  Verifying  : 1:perl-Pod-Simple-3.28-4.el7.noarch                                                     17/40
  Verifying  : perl-Time-Local-1.2300-2.el7.noarch                                                     18/40
  Verifying  : perl-Pod-Perldoc-3.20-4.el7.noarch                                                      19/40
  Verifying  : perl-DBI-1.627-4.el7.x86_64                                                             20/40
  Verifying  : libaio-0.3.109-13.el7.x86_64                                                            21/40
  Verifying  : perl-Socket-2.010-3.el7.x86_64                                                          22/40
  Verifying  : perl-Carp-1.26-244.el7.noarch                                                           23/40
  Verifying  : perl-Data-Dumper-2.145-3.el7.x86_64                                                     24/40
  Verifying  : mysql-community-client-5.6.33-2.el7.x86_64                                              25/40
  Verifying  : perl-Scalar-List-Utils-1.27-248.el7.x86_64                                              26/40
  Verifying  : 1:perl-Compress-Raw-Zlib-2.061-4.el7.x86_64                                             27/40
  Verifying  : 1:perl-Pod-Escapes-1.04-286.el7.noarch                                                  28/40
  Verifying  : perl-Pod-Usage-1.63-3.el7.noarch                                                        29/40
  Verifying  : perl-PlRPC-0.2020-14.el7.noarch                                                         30/40
  Verifying  : perl-Encode-2.51-7.el7.x86_64                                                           31/40
  Verifying  : perl-Storable-2.45-3.el7.x86_64                                                         32/40
  Verifying  : perl-podlators-2.5.1-3.el7.noarch                                                       33/40
  Verifying  : perl-Getopt-Long-2.40-2.el7.noarch                                                      34/40
  Verifying  : perl-File-Path-2.09-2.el7.noarch                                                        35/40
  Verifying  : perl-threads-1.87-4.el7.x86_64                                                          36/40
  Verifying  : perl-Filter-1.49-3.el7.x86_64                                                           37/40
  Verifying  : perl-Text-ParseWords-3.29-4.el7.noarch                                                  38/40
  Verifying  : mysql-community-libs-5.6.33-2.el7.x86_64                                                39/40
  Verifying  : 1:mariadb-libs-5.5.50-1.el7_2.x86_64                                                    40/40

Installed:
  mysql-community-libs.x86_64 0:5.6.33-2.el7           mysql-community-server.x86_64 0:5.6.33-2.el7

Dependency Installed:
  libaio.x86_64 0:0.3.109-13.el7                        mysql-community-client.x86_64 0:5.6.33-2.el7
  mysql-community-common.x86_64 0:5.6.33-2.el7          perl.x86_64 4:5.16.3-286.el7
  perl-Carp.noarch 0:1.26-244.el7                       perl-Compress-Raw-Bzip2.x86_64 0:2.061-3.el7
  perl-Compress-Raw-Zlib.x86_64 1:2.061-4.el7           perl-DBI.x86_64 0:1.627-4.el7
  perl-Data-Dumper.x86_64 0:2.145-3.el7                 perl-Encode.x86_64 0:2.51-7.el7
  perl-Exporter.noarch 0:5.68-3.el7                     perl-File-Path.noarch 0:2.09-2.el7
  perl-File-Temp.noarch 0:0.23.01-3.el7                 perl-Filter.x86_64 0:1.49-3.el7
  perl-Getopt-Long.noarch 0:2.40-2.el7                  perl-HTTP-Tiny.noarch 0:0.033-3.el7
  perl-IO-Compress.noarch 0:2.061-2.el7                 perl-Net-Daemon.noarch 0:0.48-5.el7
  perl-PathTools.x86_64 0:3.40-5.el7                    perl-PlRPC.noarch 0:0.2020-14.el7
  perl-Pod-Escapes.noarch 1:1.04-286.el7                perl-Pod-Perldoc.noarch 0:3.20-4.el7
  perl-Pod-Simple.noarch 1:3.28-4.el7                   perl-Pod-Usage.noarch 0:1.63-3.el7
  perl-Scalar-List-Utils.x86_64 0:1.27-248.el7          perl-Socket.x86_64 0:2.010-3.el7
  perl-Storable.x86_64 0:2.45-3.el7                     perl-Text-ParseWords.noarch 0:3.29-4.el7
  perl-Time-HiRes.x86_64 4:1.9725-3.el7                 perl-Time-Local.noarch 0:1.2300-2.el7
  perl-constant.noarch 0:1.27-2.el7                     perl-libs.x86_64 4:5.16.3-286.el7
  perl-macros.x86_64 4:5.16.3-286.el7                   perl-parent.noarch 1:0.225-244.el7
  perl-podlators.noarch 0:2.5.1-3.el7                   perl-threads.x86_64 0:1.87-4.el7
  perl-threads-shared.x86_64 0:1.43-6.el7

Replaced:
  mariadb-libs.x86_64 1:5.5.50-1.el7_2

Complete!
</code></pre>
</div>

<p>Start the MySQL server : (correct way is not using services)</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo systemctl start mysqld
</code></pre>
</div>

<p>Check the status of the server :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo systemctl status mysqld
</code></pre>
</div>

<p>Output:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>  ● mysqld.service - MySQL Community Server
    Loaded: loaded <span class="o">(</span>/usr/lib/systemd/system/mysqld.service; enabled; vendor preset: disabled<span class="o">)</span>
    Active: active <span class="o">(</span>running<span class="o">)</span> since Thu 2016-09-29 18:39:55 UTC; 29s ago
    Process: 12821 <span class="nv">ExecStartPost</span><span class="o">=</span>/usr/bin/mysql-systemd-start post <span class="o">(</span><span class="nv">code</span><span class="o">=</span>exited, <span class="nv">status</span><span class="o">=</span>0/SUCCESS<span class="o">)</span>
    Process: 12809 <span class="nv">ExecStartPre</span><span class="o">=</span>/usr/bin/mysql-systemd-start pre <span class="o">(</span><span class="nv">code</span><span class="o">=</span>exited, <span class="nv">status</span><span class="o">=</span>0/SUCCESS<span class="o">)</span>
  Main PID: 12820 <span class="o">(</span>mysqld_safe<span class="o">)</span>
    CGroup: /system.slice/mysqld.service
            ├─12820 /bin/sh /usr/bin/mysqld_safe
            └─12975 /usr/sbin/mysqld --basedir<span class="o">=</span>/usr --datadir<span class="o">=</span>/var/lib/mysql --plugin-dir<span class="o">=</span>/usr/lib64/mysql/plugin --log-error<span class="o">=</span>/var/log/mysqld.log --pid-file<span class="o">=</span>/var/run/mysqld/mysqld...

  Sep 29 18:39:54 ip-10-0-138-51 systemd[1]: Starting MySQL Community Server...
  Sep 29 18:39:54 ip-10-0-138-51 mysqld_safe[12820]: 160929 18:39:54 mysqld_safe Logging to <span class="s1">'/var/log/mysqld.log'</span>.
  Sep 29 18:39:54 ip-10-0-138-51 mysqld_safe[12820]: 160929 18:39:54 mysqld_safe Starting mysqld daemon with databases from /var/lib/mysql
  Sep 29 18:39:55 ip-10-0-138-51 systemd[1]: Started MySQL Community Server.
</code></pre>
</div>

<p>Connect to MySQL using root :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>mysql -u root
</code></pre>
</div>

<p>Output:
~~~
  Welcome to the MySQL monitor.  Commands end with ; or \g.
  Your MySQL connection id is 2
  Server version: 5.6.33 MySQL Community Server (GPL)</p>

<p>Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.</p>

<p>Oracle is a registered trademark of Oracle Corporation and/or its
  affiliates. Other names may be trademarks of their respective
  owners.</p>

<p>Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement.</p>

<p>mysql&gt;
~~~</p>

<p>Type : ‘exit’ to leave the MySQL shell.</p>

<p>To enable autostart on server boot :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo systemctl <span class="nb">enable </span>mysqld.service
</code></pre>
</div>

<p>Check the status again with :</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="gp">$ </span>sudo systemctl status mysqld
</code></pre>
</div>

	  ]]></description>
	</item>


</channel>
</rss>
